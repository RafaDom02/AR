{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C3PbFgd6CpS1"
      },
      "source": [
        "# GridWorld 3:\n",
        "\n",
        "*GridWorld* es un mundo en forma de cuadrícula muy utilizado como entorno de pruebas para técnicas de Aprendizaje por Refuerzo. Dentro de esta cuadrícula hay varios tipos de celdas: iniciales, libres, obstáculos, terminales... ¡y ahora también catapultas y agujeros de gusano! Los agentes tienen que llegar desde una celda inicial hasta otra terminal evitando los obtáculos y recorriendo una distancia mínima."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLz6HYMXCyID"
      },
      "source": [
        "Paquetes necesarios para *GridWorld 3*:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "aet9gV2KCe2q"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import math\n",
        "\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4fsv0HwszqX"
      },
      "source": [
        "Funciones auxiliares para visualizar información:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "awRXzniVs5pj"
      },
      "outputs": [],
      "source": [
        "def printMap(world):\n",
        "  # Visualiza el mapa de GridWorld\n",
        "  m = \"[\"\n",
        "  for i in range(world.size[0]):\n",
        "    for j in range(world.size[1]):\n",
        "      if world.map[(i, j)] == 0:\n",
        "        m += \" O \"\n",
        "      elif world.map[(i, j)] == -1:\n",
        "        m += \" X \"\n",
        "      elif world.map[(i, j)] == 1:\n",
        "        m += \" F \"\n",
        "      elif world.map[(i, j)] == 2:\n",
        "        m += \" T \"\n",
        "      elif world.map[(i, j)] == 3:\n",
        "        m += \" C \"\n",
        "    if i == world.size[0] - 1:\n",
        "      m += \"]\\n\"\n",
        "    else:\n",
        "      m += \"\\n\"\n",
        "  print(m)\n",
        "\n",
        "def printPolicy(world, policy):\n",
        "  # Visualiza la política con flechas\n",
        "  p = \"[\"\n",
        "  for i in range(world.size[0]):\n",
        "    for j in range(world.size[1]):\n",
        "      if policy[i][j] == 0:\n",
        "        p += \" ^ \"\n",
        "      elif policy[i][j] == 1:\n",
        "        p += \" V \"\n",
        "      elif policy[i][j] == 2:\n",
        "        p += \" < \"\n",
        "      elif policy[i][j] == 3:\n",
        "        p += \" > \"\n",
        "      else:\n",
        "        p += \" x \"\n",
        "    if i == world.size[0] - 1:\n",
        "      p += \"]\\n\"\n",
        "    else:\n",
        "      p += \"\\n\"\n",
        "  print(p)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELyNLQplC-W0"
      },
      "source": [
        "# Clase *World*:\n",
        "\n",
        "Esta clase almacena la información del mundo:\n",
        "\n",
        "*   *Map*: Matriz con la codificación del mundo con celdas libres (0), obstáculos (-1) y terminales (1)\n",
        "*   *Size*: Vector con el tamaño de la matriz de codificación del mundo (ancho, alto)\n",
        "\n",
        "Para crear un mundo hay que aportar los siguientes datos:\n",
        "\n",
        "*   Tamaño del mapa (ancho, alto)\n",
        "*   Lista de celdas terminales\n",
        "*   Lista de celdas con obstáculos\n",
        "*   Agujero de gusano\n",
        "*   Lista de catapultas\n",
        "\n",
        "Notas:\n",
        "\n",
        "* Cuando el agente cae en un obstáculo se queda atrapado para siempre en él\n",
        "* Cuando el agente entra por un extremo del agujero de gusano sale por el otro extremo\n",
        "* Cuando el agente cae en una catapulta avanza un número de casillas aleatorio en su dirección de movimiento\n",
        "\n",
        "Por ejemplo:\n",
        "\n",
        "w = World((10, 10), [(9, 9)], [(2, 4), (4, 2)], [(0, 2), (9, 7)], [(2, 2), (7,7)])\n",
        "\n",
        "Crea un mundo de 10 filas y 10 columnas con un estado terminal (9, 9), dos obstáculos en (2, 4) y (4, 2), un teletransporte entre (0, 2) y (9, 7) y dos catapultas en (2, 2) y (7, 7).\n",
        "\n",
        "![map2.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "v7iQbNj6C9MC"
      },
      "outputs": [],
      "source": [
        "class World:\n",
        "\n",
        "  def __init__(self, size, terminal, obstacle, hole, catapult):\n",
        "    # Crea un mundo\n",
        "    self.size = size\n",
        "    self.map = {}\n",
        "    for i in range(size[0]):\n",
        "      for j in range(size[1]):\n",
        "        # Estados libres\n",
        "        self.map[(i, j)] = 0\n",
        "        # Estados terminales\n",
        "        for t in terminal:\n",
        "          if i==t[0] and j==t[1]:\n",
        "            self.map[(i, j)] = 1\n",
        "        # Estados con obstáculos\n",
        "        for o in obstacle:\n",
        "          if i==o[0] and j==o[1]:\n",
        "            self.map[(i, j)] = -1\n",
        "        for h in hole:\n",
        "          if i==h[0] and j==h[1]:\n",
        "            self.map[(i, j)] = 2\n",
        "        for c in catapult:\n",
        "          if i==c[0] and j==c[1]:\n",
        "            self.map[(i, j)] = 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZTrYC15IHy3s"
      },
      "source": [
        "Prueba de la clase *World*:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kgBnrzsQHS8R",
        "outputId": "dabf01a0-5a97-43e3-8723-e6872334f760"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ O  O  T  O  O  O  O  O  O  O \n",
            " O  O  O  O  O  O  O  O  O  O \n",
            " O  O  C  O  X  O  O  O  O  O \n",
            " O  O  O  O  O  O  O  O  O  O \n",
            " O  O  X  O  O  O  O  O  O  O \n",
            " O  O  O  O  O  O  O  O  O  O \n",
            " O  O  O  O  O  O  O  O  O  O \n",
            " O  O  O  O  O  O  O  C  O  O \n",
            " O  O  O  O  O  O  O  O  O  O \n",
            " O  O  O  O  O  O  O  T  O  F ]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "  w = World((10, 10), [(9, 9)], [(2, 4), (4, 2)], [(0, 2), (9, 7)], [(2, 2), (7, 7)])\n",
        "  printMap(w)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4yw3UEuAI6Cv"
      },
      "source": [
        "# Clase *Agent*:\n",
        "\n",
        "Esta clase controla el agente que aprende por refuerzo en *GridWorld*.\n",
        "\n",
        "Para crear un agente se necesitan los siguientes datos:\n",
        "\n",
        "*   *World*: Mundo en el que se desenvuelve el agente.\n",
        "*   *Initial State*: Estado inicial del agente.\n",
        "\n",
        "Para controlar el agente se usan los siguientes métodos:\n",
        "\n",
        "*   *nextState = move(state, action)*: Mueve el agente del estado *state* a un nuevo estado *nextState* aplicando una acción *action*.\n",
        "*   *reward = reward(nextState)*: Devuelve el refuerzo *reward* que recibe el agente al transicionar al estado *nextState*.\n",
        "*   *nextState, reward = checkAction(state, action)*: Comprueba a qué estado *nextState* y con qué refuerzo *reward* cambia el agente al aplicar la acción *action* en el estado *state*. Este método no cambia el estado interno del agente, por lo que puede usarse para hacer barridos del espacio de estados.\n",
        "*   *nextState, reward = executeAction(action)*: Ejecuta la acción *action* en el estado actual y devuelve el nuevo estado *nextState* y el refuerzo *reward*. Este método cambia el estado interno del agente, por lo que sólo debe usarse cuando se realice un recorrido por el mundo.\n",
        "\n",
        "Nota: Podéis hacer cambios en el agente (distribución de refuerzos, comportamiento en obstáculos...) buscando mejorar el rendimiento de los algoritmos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "2as_2oTqH61U"
      },
      "outputs": [],
      "source": [
        "class Agent:\n",
        "\n",
        "  def __init__(self, world, initialState):\n",
        "    # Crea un agente\n",
        "    self.world = world\n",
        "    self.initial_state = np.array(initialState)\n",
        "    self.state = np.array(initialState)\n",
        "    \n",
        "  def reset(self):\n",
        "    # Resets agent to its initial state\n",
        "    self.state = np.array(self.initial_state)\n",
        "\n",
        "  def move(self, state, action):\n",
        "    # Gestiona las transiciones de estados\n",
        "    nextState = state + np.array(action)\n",
        "    if nextState[0] < 0:\n",
        "      nextState[0] = 0\n",
        "    elif nextState[0] >= self.world.size[0]:\n",
        "      nextState[0] = self.world.size[0] - 1\n",
        "    if nextState[1] < 0:\n",
        "      nextState[1] = 0\n",
        "    elif nextState[1] >= self.world.size[1]:\n",
        "      nextState[1] = self.world.size[1] - 1\n",
        "    if self.world.map[(nextState[0], nextState[1])] == 2:\n",
        "      aux = nextState\n",
        "      for i in range(self.world.size[0]):\n",
        "        for j in range(self.world.size[1]):\n",
        "          if self.world.map[(i, j)] == 2 and (nextState[0] != i and nextState[1] != j):\n",
        "            aux = np.array([i, j])\n",
        "            nextState = aux\n",
        "    if self.world.map[(nextState[0], nextState[1])] == 3:\n",
        "      if action == (1, 0):\n",
        "        nextState = np.array([np.random.randint(nextState[0], self.world.size[0]-1), nextState[1]])\n",
        "      elif action == (-1, 0):\n",
        "        nextState = np.array([np.random.randint(0, nextState[0]), nextState[1]])\n",
        "      elif action == (0, 1):\n",
        "        nextState = np.array([nextState[0], np.random.randint(nextState[1], self.world.size[1]-1)])\n",
        "      elif action == (0, -1):\n",
        "        nextState = np.array([nextState[0], np.random.randint(0, nextState[1])])\n",
        "    return nextState\n",
        "\n",
        "  def reward(self, nextState):\n",
        "    # Gestiona los refuerzos\n",
        "    if self.world.map[(nextState[0], nextState[1])] == -1:\n",
        "      # Refuerzo cuando el agente intenta moverse a un obstáculo\n",
        "      reward = -1 # ** Prueba varios valores **\n",
        "    elif self.world.map[(nextState[0], nextState[1])] == 1:\n",
        "      # Refuerzo cuando el agente se mueve a una celda terminal\n",
        "      reward = 1 # ** Prueba varios valores **\n",
        "    else:\n",
        "      # Refuerzo cuando el agente se mueve a una celda libre\n",
        "      reward = 0 # ** Prueba varios valores **\n",
        "    return reward\n",
        "\n",
        "  def checkAction(self, state, action):\n",
        "    # Planifica una acción\n",
        "    nextState = self.move(state, action)\n",
        "    if self.world.map[(state[0], state[1])] == -1:\n",
        "      nextState = state\n",
        "    reward = self.reward(nextState)\n",
        "    return nextState, reward\n",
        "\n",
        "  def executeAction(self, action):\n",
        "    # Planifica y ejecuta una acción\n",
        "    nextState = self.move(self.state, action)\n",
        "    if self.world.map[(self.state[0], self.state[1])] == -1:\n",
        "      nextState = self.state\n",
        "    else:\n",
        "      self.state = nextState\n",
        "    reward = self.reward(nextState)\n",
        "    return self.state, reward"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MIpqVYBwMid7"
      },
      "source": [
        "Prueba de la clase *Agent*:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UG2bfPrfJFg4",
        "outputId": "a8557c96-863b-4647-d033-0b295437596d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ O  O  T  O  O  O  O  O  O  O \n",
            " O  O  O  O  O  O  O  O  O  O \n",
            " O  O  C  O  X  O  O  O  O  O \n",
            " O  O  O  O  O  O  O  O  O  O \n",
            " O  O  X  O  O  O  O  O  O  O \n",
            " O  O  O  O  O  O  O  O  O  O \n",
            " O  O  O  O  O  O  O  O  O  O \n",
            " O  O  O  O  O  O  O  C  O  O \n",
            " O  O  O  O  O  O  O  O  O  O \n",
            " O  O  O  O  O  O  O  T  O  F ]\n",
            "\n",
            "(array([2, 1]), 0)\n",
            "(array([2, 4]), -1)\n",
            "(array([2, 4]), -1)\n",
            "(array([2, 4]), -1)\n"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "  # Crear el mundo\n",
        "  w = World((10, 10), [(9, 9)], [(2, 4), (4, 2)], [(0, 2), (9, 7)], [(2, 2), (7, 7)])\n",
        "  printMap(w)\n",
        "  # Crear el agente\n",
        "  a = Agent(w, (2, 0))\n",
        "  # Mover el agente en la diagonal principal\n",
        "  for i in range(1, 5):\n",
        "    # Mostrar cada nuevo estado y su recompensa\n",
        "    print(a.executeAction((0, 1)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q9whMl4OxJI-"
      },
      "source": [
        "# Trabajo:\n",
        "\n",
        "En este trabajo vais a implementar los dos algoritmos más comunes de aprendizaje por refuerzo basados en el valor: SARSA y QLearning. Además, vais a probar ambos algoritmos en una serie de escenarios para evaluar su funcionamiento y comparar sus resultados.\n",
        "\n",
        "## Mundos:\n",
        "\n",
        "Para probar los algoritmos se ofrecen los siguientes mundos en varios tamaños:\n",
        "\n",
        "*   Mundo 1: Laberinto fácil que se puede recorrer en zigzag\n",
        "*   Mundo 2: Mundo con obstáculos aleatorios en el que el teletransporte acorta la distancia desde el inicio hasta el final\n",
        "*   Mundo 3: Mundo con obstáculos aleatorios en el que el teletransporte no reduce la distancia desde el inicio hasta el final\n",
        "*   Mundo 4: Mundo con obstáculos aleatorios y catapultas que pueden ser útiles o no para llegar al destino.\n",
        "*   Mundo 5: Laberinto difícil con caminos correctos y equivocados\n",
        "\n",
        "Nota: Sentíos libres de utilizar todos o algunos de estos escenarios o directamente crear vuestros propios escenarios."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3f9kCBErMweC",
        "outputId": "2552e02f-1ddf-4528-e251-2d4e450080a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "World 1: \n",
            "[ O  X  O  O  O \n",
            " O  X  O  X  O \n",
            " O  X  O  X  O \n",
            " O  X  O  X  O \n",
            " O  O  O  X  F ]\n",
            "\n",
            "World 1: \n",
            "[ O  X  O  O  O  X  O  O  O \n",
            " O  X  O  X  O  X  O  X  O \n",
            " O  X  O  X  O  X  O  X  O \n",
            " O  X  O  X  O  X  O  X  O \n",
            " O  X  O  X  O  X  O  X  O \n",
            " O  X  O  X  O  X  O  X  O \n",
            " O  X  O  X  O  X  O  X  O \n",
            " O  X  O  X  O  X  O  X  O \n",
            " O  O  O  X  O  O  O  X  F ]\n",
            "\n",
            "World 1: \n",
            "[ O  X  O  O  O  X  O  O  O  X  O  O  O  X  O  O  O  X  O  O  O \n",
            " O  X  O  X  O  X  O  X  O  X  O  X  O  X  O  X  O  X  O  X  O \n",
            " O  X  O  X  O  X  O  X  O  X  O  X  O  X  O  X  O  X  O  X  O \n",
            " O  X  O  X  O  X  O  X  O  X  O  X  O  X  O  X  O  X  O  X  O \n",
            " O  X  O  X  O  X  O  X  O  X  O  X  O  X  O  X  O  X  O  X  O \n",
            " O  X  O  X  O  X  O  X  O  X  O  X  O  X  O  X  O  X  O  X  O \n",
            " O  X  O  X  O  X  O  X  O  X  O  X  O  X  O  X  O  X  O  X  O \n",
            " O  X  O  X  O  X  O  X  O  X  O  X  O  X  O  X  O  X  O  X  O \n",
            " O  X  O  X  O  X  O  X  O  X  O  X  O  X  O  X  O  X  O  X  O \n",
            " O  X  O  X  O  X  O  X  O  X  O  X  O  X  O  X  O  X  O  X  O \n",
            " O  X  O  X  O  X  O  X  O  X  O  X  O  X  O  X  O  X  O  X  O \n",
            " O  X  O  X  O  X  O  X  O  X  O  X  O  X  O  X  O  X  O  X  O \n",
            " O  X  O  X  O  X  O  X  O  X  O  X  O  X  O  X  O  X  O  X  O \n",
            " O  X  O  X  O  X  O  X  O  X  O  X  O  X  O  X  O  X  O  X  O \n",
            " O  X  O  X  O  X  O  X  O  X  O  X  O  X  O  X  O  X  O  X  O \n",
            " O  X  O  X  O  X  O  X  O  X  O  X  O  X  O  X  O  X  O  X  O \n",
            " O  X  O  X  O  X  O  X  O  X  O  X  O  X  O  X  O  X  O  X  O \n",
            " O  X  O  X  O  X  O  X  O  X  O  X  O  X  O  X  O  X  O  X  O \n",
            " O  X  O  X  O  X  O  X  O  X  O  X  O  X  O  X  O  X  O  X  O \n",
            " O  X  O  X  O  X  O  X  O  X  O  X  O  X  O  X  O  X  O  X  O \n",
            " O  O  O  X  O  O  O  X  O  O  O  X  O  O  O  X  O  O  O  X  F ]\n",
            "\n",
            "World 2: \n",
            "[ O  O  O  O  O \n",
            " O  O  O  X  O \n",
            " T  O  X  O  O \n",
            " O  X  O  O  O \n",
            " O  O  T  O  F ]\n",
            "\n",
            "World 2: \n",
            "[ O  O  O  O  O  O  O  O  O  O \n",
            " O  O  O  O  O  O  O  O  O  O \n",
            " O  O  O  O  O  O  O  O  O  O \n",
            " O  T  X  O  O  O  O  O  O  O \n",
            " O  O  O  O  X  O  O  O  X  O \n",
            " O  O  O  X  O  O  O  O  O  O \n",
            " O  O  O  X  O  O  X  X  O  O \n",
            " O  O  O  O  X  O  O  O  O  O \n",
            " O  O  O  O  O  O  T  O  X  O \n",
            " O  O  O  O  O  O  O  O  O  F ]\n",
            "\n",
            "World 2: \n",
            "[ O  O  O  O  O  O  O  O  O  O  O  O  O  O  O  O  O  O  O  O  O \n",
            " O  O  O  O  O  O  O  O  X  O  O  X  O  X  O  O  O  O  O  O  O \n",
            " O  O  O  O  O  O  O  O  O  O  O  X  O  O  O  O  O  O  O  O  O \n",
            " O  O  X  O  X  O  O  O  O  O  O  O  O  O  O  O  O  X  O  O  O \n",
            " O  O  O  X  O  O  X  O  O  O  X  O  O  O  O  O  X  O  O  O  O \n",
            " O  O  O  O  O  O  X  O  O  O  O  O  O  O  O  O  O  X  O  O  O \n",
            " O  O  T  O  O  O  X  O  O  X  O  O  O  O  X  O  O  O  O  O  O \n",
            " O  O  O  O  O  O  X  O  X  O  O  X  O  O  O  X  O  O  O  O  O \n",
            " O  X  O  O  O  O  O  O  O  O  O  O  O  O  O  O  X  X  X  O  O \n",
            " O  X  O  O  X  O  O  O  O  O  O  O  O  O  O  O  O  O  O  O  O \n",
            " O  O  O  O  O  O  O  X  O  O  X  O  O  O  O  O  O  O  O  O  O \n",
            " O  O  O  X  O  X  O  X  X  O  O  O  O  O  O  O  O  O  X  O  O \n",
            " O  O  O  O  O  O  O  O  X  O  O  O  O  O  O  O  X  O  O  O  O \n",
            " O  O  O  O  O  O  O  O  O  O  O  O  O  O  O  O  O  O  O  O  O \n",
            " O  O  O  O  O  O  O  O  O  X  O  X  O  X  O  O  O  O  O  O  O \n",
            " O  O  O  O  X  O  O  O  O  X  O  O  O  O  O  O  O  O  O  O  O \n",
            " O  O  O  O  X  O  O  O  O  O  O  O  O  O  O  O  O  O  O  O  O \n",
            " O  O  O  O  O  X  O  O  O  O  O  O  O  O  X  O  O  O  O  O  O \n",
            " O  O  O  O  O  X  O  O  O  O  O  O  O  O  T  O  O  O  O  O  O \n",
            " O  O  O  O  O  O  O  O  O  O  O  O  O  O  O  O  O  O  O  O  O \n",
            " O  O  O  O  O  O  O  O  O  O  O  O  O  O  O  O  O  O  O  O  F ]\n",
            "\n",
            "World 3: \n",
            "[ O  O  O  O  T \n",
            " O  O  X  X  O \n",
            " O  O  O  O  O \n",
            " O  O  O  O  O \n",
            " T  O  O  O  F ]\n",
            "\n",
            "World 3: \n",
            "[ O  O  O  O  O  O  O  O  O  O \n",
            " O  O  O  O  O  O  X  O  T  O \n",
            " O  O  O  O  O  O  O  O  O  O \n",
            " O  O  O  O  O  O  O  O  O  O \n",
            " O  O  O  O  O  O  X  X  O  O \n",
            " O  X  X  O  O  O  O  O  X  O \n",
            " O  O  O  O  O  O  O  O  X  O \n",
            " O  O  O  X  O  O  O  X  O  O \n",
            " O  T  O  O  O  O  O  O  O  O \n",
            " O  O  O  O  O  O  O  O  O  F ]\n",
            "\n",
            "World 3: \n",
            "[ O  O  O  O  O  O  O  O  O  O  O  O  O  O  O  O  O  O  O  O  O \n",
            " O  O  O  O  X  O  O  O  X  O  O  O  O  O  O  O  O  O  O  O  O \n",
            " O  O  O  O  O  O  O  O  O  O  O  O  O  O  O  O  O  O  T  O  O \n",
            " O  O  O  X  O  X  O  O  X  O  O  O  O  O  O  O  O  O  O  O  O \n",
            " O  X  O  O  O  O  O  X  O  O  X  O  O  O  O  X  O  X  O  O  O \n",
            " O  O  O  O  O  O  O  X  O  O  X  O  O  O  O  O  O  O  O  O  O \n",
            " O  O  O  O  O  O  O  O  O  O  O  O  O  O  O  O  O  O  O  O  O \n",
            " O  O  O  O  O  O  X  X  O  X  O  O  O  O  O  O  X  O  O  O  O \n",
            " O  O  O  O  O  O  O  O  O  O  X  X  O  X  O  O  O  O  O  O  O \n",
            " O  O  O  O  O  X  O  O  O  O  O  X  X  O  O  O  O  O  O  O  O \n",
            " O  O  O  O  O  O  O  O  O  O  O  O  O  O  O  X  O  O  O  O  O \n",
            " O  O  O  O  O  O  X  O  O  O  O  O  O  O  O  O  O  O  X  O  O \n",
            " O  O  O  O  O  O  X  O  O  X  O  O  O  O  O  O  O  O  O  O  O \n",
            " O  O  O  O  O  O  X  O  O  O  O  O  O  O  O  O  X  X  X  O  O \n",
            " O  O  O  X  O  O  X  O  O  O  X  O  O  O  O  O  O  O  X  O  O \n",
            " O  O  O  O  O  O  O  O  O  O  O  O  O  O  O  O  O  X  O  O  O \n",
            " O  O  O  O  O  O  O  O  O  O  O  O  O  O  O  O  X  O  X  O  O \n",
            " O  O  O  O  O  O  O  X  O  O  O  O  O  O  O  X  O  O  O  O  O \n",
            " O  X  T  O  X  O  O  X  O  O  X  O  O  O  O  O  O  X  X  O  O \n",
            " O  O  O  O  O  O  O  O  O  O  O  O  O  O  O  O  O  O  O  O  O \n",
            " O  O  O  O  O  O  O  O  O  O  O  O  O  O  O  O  O  O  O  O  F ]\n",
            "\n",
            "World 4: \n",
            "[ O  O  O  O  O \n",
            " O  C  O  X  O \n",
            " O  X  O  O  O \n",
            " O  O  O  O  O \n",
            " O  O  O  O  F ]\n",
            "\n",
            "World 4: \n",
            "[ O  O  O  O  O  O  O  O  O  O \n",
            " O  O  X  O  O  O  O  O  O  O \n",
            " O  O  C  O  O  O  O  O  X  O \n",
            " O  X  O  O  O  O  O  O  X  O \n",
            " O  O  O  O  O  X  X  O  O  O \n",
            " O  O  O  O  O  C  O  O  O  O \n",
            " O  O  O  X  O  O  O  O  O  O \n",
            " O  O  O  O  O  O  X  O  O  O \n",
            " O  O  O  O  O  O  O  X  O  O \n",
            " O  O  O  O  O  O  O  O  O  F ]\n",
            "\n",
            "World 4: \n",
            "[ O  O  O  O  O  O  O  O  O  O  O  O  O  O  O  O  O  O  O  O  O \n",
            " O  O  O  O  O  O  O  O  O  O  O  O  O  O  O  O  X  O  O  O  O \n",
            " O  O  C  O  O  O  O  O  O  O  O  O  O  O  X  O  O  O  O  O  O \n",
            " O  O  O  O  O  O  O  O  O  O  X  O  X  O  O  O  O  O  O  O  O \n",
            " O  O  X  O  O  O  X  O  O  O  O  O  O  O  O  O  O  O  O  O  O \n",
            " O  O  X  O  O  C  O  X  X  O  O  O  X  O  O  O  O  O  O  O  O \n",
            " O  X  O  O  X  O  O  O  O  X  O  O  O  O  O  O  O  O  O  O  O \n",
            " O  O  O  O  O  O  O  O  O  X  O  O  O  O  O  X  O  O  X  O  O \n",
            " O  O  O  O  O  O  O  O  O  O  O  O  O  O  X  X  O  O  O  O  O \n",
            " O  O  O  X  O  O  O  O  O  O  X  X  O  O  O  O  O  O  O  O  O \n",
            " O  O  O  X  O  X  O  O  O  O  X  O  O  O  X  O  O  O  O  O  O \n",
            " O  O  O  O  O  O  O  O  O  O  O  X  O  X  X  O  O  O  O  O  O \n",
            " O  O  O  O  X  O  O  O  X  O  O  O  C  O  X  O  O  O  O  O  O \n",
            " O  O  O  O  O  X  O  O  O  O  O  O  X  X  O  O  O  X  O  O  O \n",
            " O  O  X  O  O  O  O  O  O  O  O  O  O  X  O  O  X  O  O  O  O \n",
            " O  O  O  O  O  O  O  O  O  O  O  O  X  O  O  C  O  O  O  O  O \n",
            " O  O  O  X  O  O  O  O  X  O  O  O  O  O  O  O  O  O  O  O  O \n",
            " O  O  O  O  O  X  O  O  O  X  O  X  X  O  O  O  O  O  O  O  O \n",
            " O  O  O  O  O  O  O  O  O  O  O  O  X  O  X  O  O  O  O  O  O \n",
            " O  O  O  O  O  O  O  O  O  O  O  O  O  O  O  O  O  O  O  O  O \n",
            " O  O  O  O  O  O  O  O  O  O  O  O  O  O  O  O  O  O  O  O  F ]\n",
            "\n",
            "World 5: \n",
            "[ O  X  O  X  O  O  O  O  O  X  O  O  O  O  O  X  X  X  O  X  O \n",
            " O  X  O  X  X  X  X  X  O  X  X  X  X  X  O  O  O  X  O  X  O \n",
            " O  X  O  O  O  O  O  O  O  X  O  O  O  X  O  X  X  X  O  X  O \n",
            " O  X  O  X  O  X  O  X  O  X  O  X  O  O  O  O  X  O  O  X  O \n",
            " O  O  O  X  O  X  O  X  X  X  X  X  X  X  X  O  X  O  X  X  O \n",
            " X  X  X  X  O  X  O  O  O  X  O  O  O  O  O  O  X  O  O  O  O \n",
            " O  O  O  O  O  X  X  X  O  X  X  X  X  X  X  O  X  X  O  X  O \n",
            " X  X  X  X  O  X  O  X  O  X  O  O  O  O  O  O  O  O  O  X  O \n",
            " O  O  O  X  O  O  O  X  X  X  O  O  X  X  X  X  X  X  X  X  O \n",
            " O  X  O  X  O  X  O  X  O  O  O  X  X  O  O  O  O  O  O  X  X \n",
            " O  X  O  X  O  X  X  X  O  X  O  X  O  O  X  X  X  X  O  O  O \n",
            " O  X  O  X  O  X  O  O  O  X  O  X  O  X  X  O  O  X  X  X  O \n",
            " O  X  O  O  O  X  X  O  X  X  O  X  O  X  O  O  O  O  O  X  O \n",
            " O  X  X  X  X  X  O  O  X  O  O  O  O  O  O  X  X  X  O  X  O \n",
            " O  O  O  O  X  O  O  X  X  O  X  O  X  X  O  X  O  O  O  X  O \n",
            " X  X  X  O  O  O  X  X  O  O  X  O  O  X  X  X  O  X  X  X  X \n",
            " O  O  X  X  O  X  X  X  X  X  X  X  O  O  O  X  O  X  O  O  O \n",
            " X  O  O  X  O  X  O  O  O  X  O  O  O  X  X  X  O  X  O  X  O \n",
            " X  X  O  O  O  X  X  X  O  X  X  X  O  O  O  X  O  O  O  X  O \n",
            " O  X  X  O  X  X  O  O  O  O  O  X  O  X  X  X  X  X  X  X  O \n",
            " O  O  O  O  O  O  O  X  X  X  O  X  O  O  O  O  O  O  O  X  F ]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "\n",
        "  # Mundo 1 pequeño: Laberinto fácil\n",
        "  obstacles = []\n",
        "  for j in range(0, 4):\n",
        "    obstacles.append((j, 1))\n",
        "  for j in range(1, 5):\n",
        "    obstacles.append((j, 3))\n",
        "  w1p = World((5, 5), [(4, 4)], obstacles, [], [])\n",
        "  print(\"World 1: \")\n",
        "  printMap(w1p)\n",
        "\n",
        "  # Mundo 1 mediano: Laberinto fácil\n",
        "  obstacles = []\n",
        "  for i in [1, 5]:\n",
        "    for j in range(0, 8):\n",
        "      obstacles.append((j, i))\n",
        "  for i in [3, 7]:\n",
        "    for j in range(1, 9):\n",
        "      obstacles.append((j, i))\n",
        "  w1m = World((9, 9), [(8, 8)], obstacles, [], [])\n",
        "  print(\"World 1: \")\n",
        "  printMap(w1m)\n",
        "\n",
        "  # Mundo 1 grande: Laberinto fácil\n",
        "  obstacles = []\n",
        "  for i in [1, 5, 9, 13, 17]:\n",
        "    for j in range(0, 20):\n",
        "      obstacles.append((j, i))\n",
        "  for i in [3, 7, 11, 15, 19]:\n",
        "    for j in range(1, 21):\n",
        "      obstacles.append((j, i))\n",
        "  w1g = World((21, 21), [(20, 20)], obstacles, [], [])\n",
        "  print(\"World 1: \")\n",
        "  printMap(w1g)\n",
        "\n",
        "  # Mundo 2 pequeño: Obstáculos aleatorios, teletransporte útil\n",
        "  obstacles = []\n",
        "  for i in range(3):\n",
        "    obstacles.append((np.random.randint(1, 4), np.random.randint(1, 4)))\n",
        "  w2p = World((5, 5), [(4, 4)], obstacles, [(2, 0), (4, 2)], [])\n",
        "  print(\"World 2: \")\n",
        "  printMap(w2p)\n",
        "\n",
        "  # Mundo 2 mediano: Obstáculos aleatorios, teletransporte útil\n",
        "  obstacles = []\n",
        "  for i in range(10):\n",
        "    obstacles.append((np.random.randint(1, 9), np.random.randint(1, 9)))\n",
        "  w2m = World((10, 10), [(9, 9)], obstacles, [(3, 1), (8, 6)], [])\n",
        "  print(\"World 2: \")\n",
        "  printMap(w2m)\n",
        "\n",
        "  # Mundo 2 grande: Obstáculos aleatorios, teletransporte útil\n",
        "  obstacles = []\n",
        "  for i in range(50):\n",
        "    obstacles.append((np.random.randint(1, 19), np.random.randint(1, 19)))\n",
        "  w2g = World((21, 21), [(20, 20)], obstacles, [(6, 2), (18, 14)], [])\n",
        "  print(\"World 2: \")\n",
        "  printMap(w2g)\n",
        "\n",
        "  # Mundo 3 pequeño: Obstáculos aleatorios, teletransporte inútil\n",
        "  obstacles = []\n",
        "  for i in range(3):\n",
        "    obstacles.append((np.random.randint(1, 4), np.random.randint(1, 4)))\n",
        "  w3p = World((5, 5), [(4, 4)], obstacles, [(4, 0), (0, 4)], [])\n",
        "  print(\"World 3: \")\n",
        "  printMap(w3p)\n",
        "\n",
        "  # Mundo 3 mediano: Obstáculos aleatorios, teletransporte inútil\n",
        "  obstacles = []\n",
        "  for i in range(10):\n",
        "    obstacles.append((np.random.randint(1, 9), np.random.randint(1, 9)))\n",
        "  w3m = World((10, 10), [(9, 9)], obstacles, [(8, 1), (1, 8)], [])\n",
        "  print(\"World 3: \")\n",
        "  printMap(w3m)\n",
        "\n",
        "  # Mundo 3 grande: Obstáculos aleatorios, teletransporte inútil\n",
        "  obstacles = []\n",
        "  for i in range(50):\n",
        "    obstacles.append((np.random.randint(1, 19), np.random.randint(1, 19)))\n",
        "  w3g = World((21, 21), [(20, 20)], obstacles, [(18, 2), (2, 18)], [])\n",
        "  print(\"World 3: \")\n",
        "  printMap(w3g)\n",
        "\n",
        "  # Mundo 4 pequeño: Obstáculos aleatorios, teletransporte inútil\n",
        "  obstacles = []\n",
        "  for i in range(3):\n",
        "    obstacles.append((np.random.randint(1, 4), np.random.randint(1, 4)))\n",
        "  w4p = World((5, 5), [(4, 4)], obstacles, [], [(1, 1)])\n",
        "  print(\"World 4: \")\n",
        "  printMap(w4p)\n",
        "\n",
        "  # Mundo 4 mediano: Obstáculos aleatorios, teletransporte inútil\n",
        "  obstacles = []\n",
        "  for i in range(10):\n",
        "    obstacles.append((np.random.randint(1, 9), np.random.randint(1, 9)))\n",
        "  w4m = World((10, 10), [(9, 9)], obstacles, [], [(2, 2), (5, 5)])\n",
        "  print(\"World 4: \")\n",
        "  printMap(w4m)\n",
        "\n",
        "  # Mundo 4 grande: Obstáculos aleatorios, teletransporte inútil\n",
        "  obstacles = []\n",
        "  for i in range(50):\n",
        "    obstacles.append((np.random.randint(1, 19), np.random.randint(1, 19)))\n",
        "  w4g = World((21, 21), [(20, 20)], obstacles, [], [(2, 2), (5, 5), (12, 12), (15, 15)])\n",
        "  print(\"World 4: \")\n",
        "  printMap(w4g)\n",
        "\n",
        "  # Mundo 5: Laberinto difícil\n",
        "  obstacles = [(0,1),(0,3),(0,9),(0,15),(0,16),(0,17),(0,19),\n",
        "               (1,1),(1,3),(1,4),(1,5),(1,6),(1,7),(1,9),(1,10),(1,11),(1,12),(1,13),(1,17),(1,19),\n",
        "               (2,1),(2,9),(2,13),(2,15),(2,16),(2,17),(2,19),\n",
        "               (3,1),(3,3),(3,5),(3,7),(3,9),(3,11),(3,16),(3,19),\n",
        "               (4,3),(4,5),(4,7),(4,8),(4,9),(4,10),(4,11),(4,12),(4,13),(4,14),(4,16),(4,18),(4,19),\n",
        "               (5,0),(5,1),(5,2),(5,3),(5,5),(5,9),(5,16),\n",
        "               (6,5),(6,6),(6,7),(6,9),(6,10),(6,11),(6,12),(6,13),(6,14),(6,16),(6,17),(6,19),\n",
        "               (7,0),(7,1),(7,2),(7,3),(7,5),(7,7),(7,9),(7,19),\n",
        "               (8,3),(8,7),(8,8),(8,9),(8,12),(8,13),(8,14),(8,15),(8,16),(8,17),(8,18),(8,19),\n",
        "               (9,1),(9,3),(9,5),(9,7),(9,11),(9,12),(9,19),(9,20),\n",
        "               (10,1),(10,3),(10,5),(10,6),(10,7),(10,9),(10,11),(10,14),(10,15),(10,16),(10,17),\n",
        "               (11,1),(11,3),(11,5),(11,9),(11,11),(11,13),(11,14),(11,17),(11,18),(11,19),\n",
        "               (12,1),(12,5),(12,6),(12,8),(12,9),(12,11),(12,13),(12,19),\n",
        "               (13,1),(13,2),(13,3),(13,4),(13,5),(13,8),(13,15),(13,16),(13,17),(13,19),\n",
        "               (14,4),(14,7),(14,8),(14,10),(14,12),(14,13),(14,15),(14,19),\n",
        "               (15,0),(15,1),(15,2),(15,6),(15,7),(15,10),(15,13),(15,14),(15,15),(15,17),(15,18),(15,19),(15,20),\n",
        "               (16,2),(16,3),(16,5),(16,6),(16,7),(16,8),(16,9),(16,10),(16,11),(16,15),(16,17),\n",
        "               (17,0),(17,3),(17,5),(17,9),(17,13),(17,14),(17,15),(17,17),(17,19),\n",
        "               (18,0),(18,1),(18,5),(18,6),(18,7),(18,9),(18,10),(18,11),(18,15),(18,19),\n",
        "               (19,1),(19,2),(19,4),(19,5),(19,11),(19,13),(19,14),(19,15),(19,16),(19,17),(19,18),(19,19),\n",
        "               (20,7),(20,8),(20,9),(20,11),(20,19)]\n",
        "  print(\"World 5: \")\n",
        "  w5 = World((21, 21), [(20, 20)], obstacles, [], [])\n",
        "  printMap(w5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RBuT8CQk17QE"
      },
      "source": [
        "## SARSA:\n",
        "\n",
        "*SARSA* (State-Action-Reward-State-Action) es un método basado en el valor que permite resolver problemas de aprendizaje por refuerzo. Al igual que el resto de métodos basados en el valor, *SARSA* calcula de forma iterativa la función de valor $Q(S,A)$ y, a partir de ella, determina la política óptima $\\pi$.\n",
        "\n",
        "*SARSA* recibe su nombre de las cinco variables implicadas en su función de actualización: el estado actual ($S_t$), la acción actual ($A_t$), el refuerzo actual ($R_t$), el siguiente estado ($S_{t+1}$) y la siguiente acción ($A_{t+1}$). Esta función de actualización tiene la siguiente forma:\n",
        "\n",
        "\\begin{equation}\n",
        "Q(S_t,A_t) \\leftarrow Q(S_t,A_t) + \\alpha [R_t + \\gamma Q(S_{t+1}, A_{t+1}) - Q(S_t,A_t)]\n",
        "\\end{equation}\n",
        "\n",
        "Nota: $\\alpha$ es la longitud del episodio y $\\gamma$ el factor de descuento.\n",
        "\n",
        "El algoritmo *SARSA* sigue el siguiente esquema:\n",
        "\n",
        "1.   Inicializar $Q(S,A)$ para todos los estados y acciones\n",
        "2.   **Bucle** (repetir $3-9$ hasta la convergencia):\n",
        "3.   Inicializar $S_t$\n",
        "4.   Elegir $A_t$ en $S_t$ siguiendo la política derivada de $Q(S,A)$\n",
        "5.   **Bucle** (repetir $6-9$ hasta que $S_t$ sea terminal):\n",
        "6.   Tomar la acción $A_t$ en $S_t$ y observar $R_t$ y $S_{t+1}$\n",
        "7.   Elegir $A_{t+1}$ en $S_{t+1}$ siguiendo la política derivada de $Q(S,A)$\n",
        "8.   Actualizar el valor $Q(S_t, A_t)$ con la función de actualización\n",
        "9.   Tomar $S_{t+1}$ y $A_{t+1}$ como los nuevos $S_t$ y $A_t$\n",
        "\n",
        "El algoritmo *SARSA* utiliza un parámetro $\\epsilon \\in (0, 1)$ para buscar un equilibrio entre exploración y explotación. A la hora de elegir $A_t$ en $S_t$, si un número aleatorio es menor que $\\epsilon$, el algoritmo tomará una acción aleatoria; mientras que si ese número aleatorio es mayor que $\\epsilon$, el algoritmo tomará la mejor acción conocida."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-aKUuoX_Ut-"
      },
      "source": [
        "## Q-Learning:\n",
        "\n",
        "*Q-Learning* es el método más conocido para resolver problemas de aprendizaje por refuerzo mediante un esquema basado en el valor. Este algoritmo recibe su nombre directamente de $Q(S,A)$, la función de valor que va actualizando a lo largo de su ejecución. *Q-Learning* es muy parecido a *SARSA*, pero tiene una función de actualización diferente:\n",
        "\n",
        "\\begin{equation}\n",
        "Q(S_t,A_t) \\leftarrow Q(S_t,A_t) + \\alpha [R_t + \\gamma max_a{Q(S_{t+1}}, a) - Q(S_t,A_t)]\n",
        "\\end{equation}\n",
        "\n",
        "En este caso, la acción $A_{t+1}$ en $S_{t+1}$ se toma buscando el máximo valor, en lugar de poder elegir entre exploración o explotación.\n",
        "\n",
        "El algoritmo *Q-Learning* sigue el siguiente esquema:\n",
        "\n",
        "1.   Inicializar $Q(S,A)$ para todos los estados y acciones\n",
        "2.   **Bucle** (repetir $3-8$ hasta la convergencia):\n",
        "3.   Inicializar $S_t$\n",
        "4.   **Bucle** (repetir $6-8$ hasta que $S_t$ sea terminal):\n",
        "5.   Elegir $A_t$ en $S_t$ siguiendo la política derivada de $Q(S,A)$\n",
        "6.   Tomar la acción $A_t$ en $S_t$ y observar $R_t$ y $S_{t+1}$\n",
        "7.   Actualizar el valor $Q(S_t, A_t)$ con la función de actualización\n",
        "8.   Tomar $S_{t+1}$ como el nuevo $S_t$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-ctLsQcyJyv"
      },
      "source": [
        "## Ejercicio 1:\n",
        "Implementad los algoritmos SARSA y Q-Learning para el agente y entorno definidos anteriormente"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- Acciones posibles ---\n",
        "ACTIONS = [\n",
        "    (-1, 0),  # Arriba\n",
        "    (1, 0),   # Abajo\n",
        "    (0, -1),  # Izquierda\n",
        "    (0, 1)    # Derecha\n",
        "]\n",
        "\n",
        "SEED = 420\n",
        "INITIAL_STATE = (0, 0)\n",
        "\n",
        "# --- Funciones Auxiliares ---\n",
        "\n",
        "class TemporalDifferenceLearner:\n",
        "    \"\"\"\n",
        "    Clase para aprendizaje por diferencia temporal (SARSA o Q-Learning).\n",
        "    \"\"\"\n",
        "    def __init__(self, world, agent_class, actions, config):\n",
        "        \"\"\"\n",
        "        Inicializa el aprendiz TD.\n",
        "\n",
        "        Args:\n",
        "            world (World): Entorno grid.\n",
        "            agent_class (type): Clase del agente.\n",
        "            actions (list): Lista de tuplas de coordenadas de acciones.\n",
        "            config (dict): Hiperparámetros y configuraciones.\n",
        "        \"\"\"\n",
        "        self.world = world\n",
        "        self.actions = actions\n",
        "        self.num_actions = len(actions)\n",
        "        self._validate_and_set_config(config)\n",
        "\n",
        "        self.agent = agent_class(world, self.config['initial_state'])\n",
        "        self.q_table = np.zeros((*self.world.size, self.num_actions), dtype=float)\n",
        "        self.rng = np.random.default_rng(self.config['seed'])\n",
        "\n",
        "        # Variables de seguimiento\n",
        "        self.episode_rewards = []\n",
        "        self.episode_steps = []\n",
        "        self.best_q_table = None\n",
        "        self.best_path_length = float('inf')\n",
        "        self.converged_episode = -1\n",
        "        self.total_episodes_run = 0\n",
        "        self.current_epsilon = self.config['initial_epsilon']\n",
        "\n",
        "    def _validate_and_set_config(self, config):\n",
        "        \"\"\"Establece y valida los valores de configuración por defecto.\"\"\"\n",
        "        defaults = {\n",
        "            'learning_rate': 0.1,         # Tasa de aprendizaje (alpha)\n",
        "            'discount_factor': 0.99,      # Factor de descuento (gamma)\n",
        "            'initial_epsilon': 0.2,       # Tasa inicial de exploración\n",
        "            'epsilon_decay': 0.995,       # Factor de decaimiento de epsilon\n",
        "            'min_epsilon': 0.01,          # Valor mínimo de epsilon\n",
        "            'epsilon_decay_interval': 50, # Intervalo (en episodios) para decaer epsilon\n",
        "            'num_episodes': 1000,         # Número total de episodios\n",
        "            'max_steps_per_episode': self.world.size[0] * self.world.size[1] * 2,  # Límite de pasos\n",
        "            'seed': SEED,                 # Semilla aleatoria\n",
        "            'update_rule': 'q_learning',  # 'q_learning' o 'sarsa'\n",
        "            'verbose': False,             # Mostrar progreso y políticas\n",
        "            'eval_interval': 50,          # Intervalo de evaluación en episodios\n",
        "            'initial_state': INITIAL_STATE  # Posición inicial del agente\n",
        "        }\n",
        "        defaults.update(config)\n",
        "        self.config = defaults\n",
        "        if self.config['update_rule'] not in ['q_learning', 'sarsa']:\n",
        "            raise ValueError(\"config['update_rule'] debe ser 'q_learning' o 'sarsa'\")\n",
        "        print(f\"Configuración del aprendiz: {self.config}\")\n",
        "\n",
        "    def _select_action(self, state_tuple):\n",
        "        \"\"\"Selecciona una acción con estrategia epsilon-greedy.\"\"\"\n",
        "        if self.world.map[state_tuple] in [1, -1]:\n",
        "            return -1  # Estado terminal u obstáculo\n",
        "\n",
        "        if self.rng.random() < self.current_epsilon:\n",
        "            return self.rng.choice(self.num_actions)  # Explorar\n",
        "        else:\n",
        "            q_values = self.q_table[state_tuple[0], state_tuple[1], :]\n",
        "            max_q = np.max(q_values)\n",
        "            best_action_indices = np.where(np.isclose(q_values, max_q))[0]\n",
        "            if not len(best_action_indices):\n",
        "                return self.rng.choice(self.num_actions)\n",
        "            return self.rng.choice(best_action_indices)\n",
        "\n",
        "    def _apply_update(self, state_tuple, action_index, reward, next_state_tuple, next_action_index):\n",
        "        \"\"\"\n",
        "        Aplica la actualización TD (SARSA o Q-Learning) a la Q-table.\n",
        "        \"\"\"\n",
        "        current_q = self.q_table[state_tuple[0], state_tuple[1], action_index]\n",
        "        alpha = self.config['learning_rate']\n",
        "        gamma = self.config['discount_factor']\n",
        "        target_q_next = 0.0  # Valor Q por defecto para estados terminales u obstáculos\n",
        "\n",
        "        is_next_terminal = (self.world.map.get(next_state_tuple, 0) in [1, -1])\n",
        "        if not is_next_terminal:\n",
        "            if self.config['update_rule'] == 'sarsa':\n",
        "                if next_action_index != -1:\n",
        "                    target_q_next = self.q_table[next_state_tuple[0], next_state_tuple[1], next_action_index]\n",
        "            elif self.config['update_rule'] == 'q_learning':\n",
        "                target_q_next = np.max(self.q_table[next_state_tuple[0], next_state_tuple[1], :])\n",
        "\n",
        "        td_target = reward + gamma * target_q_next\n",
        "        td_error = td_target - current_q\n",
        "        self.q_table[state_tuple[0], state_tuple[1], action_index] = current_q + alpha * td_error\n",
        "\n",
        "    def run_single_episode(self, episode_num):\n",
        "        \"\"\"Ejecuta un episodio del algoritmo de aprendizaje.\"\"\"\n",
        "        self.agent.reset()\n",
        "        state_tuple = tuple(self.agent.state)\n",
        "        action_index = self._select_action(state_tuple)\n",
        "\n",
        "        if action_index == -1:\n",
        "            return 0, 0\n",
        "\n",
        "        accumulated_reward = 0.0\n",
        "        steps_taken = 0\n",
        "\n",
        "        while steps_taken < self.config['max_steps_per_episode']:\n",
        "            current_state_tuple = tuple(self.agent.state)\n",
        "            if self.world.map[current_state_tuple] in [1, -1]:\n",
        "                break\n",
        "\n",
        "            action_coords = self.actions[action_index]\n",
        "            next_state_array, reward = self.agent.checkAction(np.array(current_state_tuple), action_coords)\n",
        "            next_state_tuple = tuple(next_state_array)\n",
        "            accumulated_reward += reward\n",
        "\n",
        "            next_action_index = self._select_action(next_state_tuple)\n",
        "            self._apply_update(current_state_tuple, action_index, reward, next_state_tuple, next_action_index)\n",
        "\n",
        "            # Actualiza el estado del agente\n",
        "            self.agent.state = next_state_array\n",
        "\n",
        "            action_index = next_action_index\n",
        "            steps_taken += 1\n",
        "\n",
        "            if action_index == -1:\n",
        "                break\n",
        "\n",
        "        if (episode_num + 1) % self.config['epsilon_decay_interval'] == 0 and self.current_epsilon > self.config['min_epsilon']:\n",
        "            self.current_epsilon *= self.config['epsilon_decay']\n",
        "            self.current_epsilon = max(self.config['min_epsilon'], self.current_epsilon)\n",
        "\n",
        "        return accumulated_reward, steps_taken\n",
        "\n",
        "    def train(self):\n",
        "        \"\"\"Realiza el ciclo principal de entrenamiento.\"\"\"\n",
        "        print(f\"\\n--- Iniciando Entrenamiento ({self.config['update_rule']}) ---\")\n",
        "        self.current_epsilon = self.config['initial_epsilon']\n",
        "        start_time = time.time()\n",
        "        found_goal_policy = False\n",
        "\n",
        "        for episode in range(self.config['num_episodes']):\n",
        "            self.total_episodes_run = episode + 1\n",
        "            reward, steps = self.run_single_episode(episode)\n",
        "            self.episode_rewards.append(reward)\n",
        "            self.episode_steps.append(steps)\n",
        "\n",
        "            if (episode + 1) % self.config['eval_interval'] == 0 or episode == self.config['num_episodes'] - 1:\n",
        "                avg_reward_recent = np.mean(self.episode_rewards[-(self.config['eval_interval']):])\n",
        "                print(f\"Ep: {episode + 1}/{self.config['num_episodes']} | \"\n",
        "                      f\"Pasos: {steps} | Recompensa: {reward:.2f} | \"\n",
        "                      f\"Promedio (últimos {self.config['eval_interval']}): {avg_reward_recent:.2f} | \"\n",
        "                      f\"Epsilon: {self.current_epsilon:.4f}\")\n",
        "\n",
        "                current_policy = self.get_policy()\n",
        "                reached_goal, path_len, eval_reward = self.evaluate_policy(current_policy)\n",
        "\n",
        "                if self.config['verbose']:\n",
        "                    print(\"Política actual:\")\n",
        "                    printPolicy(self.world, current_policy)\n",
        "\n",
        "                if reached_goal:\n",
        "                    found_goal_policy = True\n",
        "                    print(f\"Evaluación: ¡Meta alcanzada! Longitud del camino: {path_len}, Recompensa: {eval_reward:.2f}\")\n",
        "                    if path_len != -1 and path_len < self.best_path_length:\n",
        "                        print(f\"*** Nueva mejor política encontrada (Longitud: {path_len}) ***\")\n",
        "                        self.best_path_length = path_len\n",
        "                        self.best_q_table = self.q_table.copy()\n",
        "                        self.converged_episode = episode + 1\n",
        "                else:\n",
        "                    print(\"Evaluación: Meta no alcanzada.\")\n",
        "\n",
        "        end_time = time.time()\n",
        "        print(f\"\\n--- Entrenamiento finalizado en {end_time - start_time:.2f} segundos ---\")\n",
        "\n",
        "        if self.best_q_table is not None:\n",
        "            print(f\"La mejor política (episodio {self.converged_episode}) tiene longitud: {self.best_path_length}\")\n",
        "            self.q_table = self.best_q_table\n",
        "            return True, self.converged_episode, self.best_path_length\n",
        "        elif found_goal_policy:\n",
        "            print(\"Se encontró una política que alcanza la meta, pero sin mejoras registradas. Usando la Q-table final.\")\n",
        "            final_policy = self.get_policy()\n",
        "            reached_goal, path_len, _ = self.evaluate_policy(final_policy)\n",
        "            if reached_goal:\n",
        "                print(f\"La política final alcanza la meta con longitud {path_len}.\")\n",
        "                return True, self.total_episodes_run, path_len\n",
        "            else:\n",
        "                print(\"La política final no alcanza la meta.\")\n",
        "                return False, self.total_episodes_run, -1\n",
        "        else:\n",
        "            print(\"No se encontró ninguna política que alcance la meta durante el entrenamiento.\")\n",
        "            return False, self.total_episodes_run, -1\n",
        "\n",
        "    def get_policy(self):\n",
        "        \"\"\"Extrae la política greedy de la Q-table actual.\"\"\"\n",
        "        policy_grid = np.full(self.world.size, -1, dtype=int)\n",
        "        rows, cols = self.world.size\n",
        "\n",
        "        for r in range(rows):\n",
        "            for c in range(cols):\n",
        "                state_tuple = (r, c)\n",
        "                if self.world.map.get(state_tuple, 0) not in [1, -1]:\n",
        "                    policy_grid[r, c] = np.argmax(self.q_table[r, c, :])\n",
        "\n",
        "        return policy_grid\n",
        "\n",
        "    def evaluate_policy(self, policy_grid):\n",
        "        \"\"\"\n",
        "        Evalúa la política ejecutando al agente en el entorno.\n",
        "\n",
        "        Args:\n",
        "            policy_grid (np.ndarray): Matriz con el índice de acción para cada estado.\n",
        "\n",
        "        Returns:\n",
        "            tuple: (meta_alcanzada (bool), longitud_camino (int), recompensa_acumulada (float))\n",
        "                   La longitud del camino es -1 si la meta no se alcanza.\n",
        "        \"\"\"\n",
        "        eval_agent = self.agent.__class__(self.world, self.config['initial_state'])\n",
        "        eval_agent.reset()\n",
        "        state_tuple = tuple(eval_agent.state)\n",
        "        accumulated_reward = 0.0\n",
        "        path_length = 0\n",
        "        max_eval_steps = self.world.size[0] * self.world.size[1] * 2\n",
        "\n",
        "        for step in range(max_eval_steps):\n",
        "            if self.world.map[state_tuple] == 1:\n",
        "                return True, path_length, accumulated_reward\n",
        "            if self.world.map[state_tuple] == -1:\n",
        "                return False, -1, accumulated_reward\n",
        "\n",
        "            action_index = policy_grid[state_tuple[0], state_tuple[1]]\n",
        "            if action_index == -1:\n",
        "                return False, -1, accumulated_reward\n",
        "\n",
        "            action_coords = self.actions[action_index]\n",
        "            next_state_array, reward = eval_agent.checkAction(np.array(state_tuple), action_coords)\n",
        "            eval_agent.state = next_state_array\n",
        "            state_tuple = tuple(eval_agent.state)\n",
        "            accumulated_reward += reward\n",
        "            path_length += 1\n",
        "\n",
        "        return False, -1, accumulated_reward\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "KgdGqN3pCDeK"
      },
      "outputs": [],
      "source": [
        "def run_sarsa_new(world, agent_class, actions, config_override={}):\n",
        "    \"\"\"Helper function to run SARSA using the TemporalDifferenceLearner.\"\"\"\n",
        "    config = {\n",
        "        'update_rule': 'sarsa',\n",
        "        'initial_state': INITIAL_STATE, # Ensure it uses the global default or override\n",
        "        'seed': SEED\n",
        "    }\n",
        "    config.update(config_override) # Apply any user overrides\n",
        "    learner = TemporalDifferenceLearner(world, agent_class, actions, config)\n",
        "    learner.train()\n",
        "    policy = learner.get_policy()\n",
        "    return policy, learner"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "def run_q_learning_new(world, agent_class, actions, config_override={}):\n",
        "    \"\"\"Helper function to run Q-Learning using the TemporalDifferenceLearner.\"\"\"\n",
        "    config = {\n",
        "        'update_rule': 'q_learning',\n",
        "        'initial_state': INITIAL_STATE, # Ensure it uses the global default or override\n",
        "        'seed': SEED\n",
        "    }\n",
        "    config.update(config_override) # Apply any user overrides\n",
        "    learner = TemporalDifferenceLearner(world, agent_class, actions, config)\n",
        "    learner.train()\n",
        "    policy = learner.get_policy()\n",
        "    return policy, learner"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ O  X  O  O  O  X  O  O  O \n",
            " O  X  O  X  O  X  O  X  O \n",
            " O  X  O  X  O  X  O  X  O \n",
            " O  X  O  X  O  X  O  X  O \n",
            " O  X  O  X  O  X  O  X  O \n",
            " O  X  O  X  O  X  O  X  O \n",
            " O  X  O  X  O  X  O  X  O \n",
            " O  X  O  X  O  X  O  X  O \n",
            " O  O  O  X  O  O  O  X  F ]\n",
            "\n",
            "\n",
            "Selected World: Map shown above.\n",
            "Agent Initial State: (0, 0)\n",
            "------------------------------\n",
            "\n",
            "========================================\n",
            "RUNNING NEW SARSA IMPLEMENTATION\n",
            "========================================\n",
            "Configuración del aprendiz: {'learning_rate': 0.15, 'discount_factor': 0.98, 'initial_epsilon': 0.3, 'epsilon_decay': 0.997, 'min_epsilon': 0.02, 'epsilon_decay_interval': 20, 'num_episodes': 4000, 'max_steps_per_episode': 243, 'seed': 420, 'update_rule': 'q_learning', 'verbose': False, 'eval_interval': 100, 'initial_state': (0, 0)}\n",
            "\n",
            "--- Iniciando Entrenamiento (q_learning) ---\n",
            "Ep: 100/4000 | Pasos: 13 | Recompensa: -1.00 | Promedio (últimos 100): -1.00 | Epsilon: 0.2955\n",
            "Evaluación: Meta no alcanzada.\n",
            "Ep: 200/4000 | Pasos: 19 | Recompensa: -1.00 | Promedio (últimos 100): -1.00 | Epsilon: 0.2911\n",
            "Evaluación: Meta no alcanzada.\n",
            "Ep: 300/4000 | Pasos: 29 | Recompensa: -1.00 | Promedio (últimos 100): -1.00 | Epsilon: 0.2868\n",
            "Evaluación: Meta no alcanzada.\n",
            "Ep: 400/4000 | Pasos: 6 | Recompensa: -1.00 | Promedio (últimos 100): -1.00 | Epsilon: 0.2825\n",
            "Evaluación: Meta no alcanzada.\n",
            "Ep: 500/4000 | Pasos: 62 | Recompensa: -1.00 | Promedio (últimos 100): -1.00 | Epsilon: 0.2783\n",
            "Evaluación: Meta no alcanzada.\n",
            "Ep: 600/4000 | Pasos: 22 | Recompensa: -1.00 | Promedio (últimos 100): -1.00 | Epsilon: 0.2741\n",
            "Evaluación: Meta no alcanzada.\n",
            "Ep: 700/4000 | Pasos: 61 | Recompensa: -1.00 | Promedio (últimos 100): -1.00 | Epsilon: 0.2701\n",
            "Evaluación: Meta no alcanzada.\n",
            "Ep: 800/4000 | Pasos: 37 | Recompensa: -1.00 | Promedio (últimos 100): -1.00 | Epsilon: 0.2660\n",
            "Evaluación: Meta no alcanzada.\n",
            "Ep: 900/4000 | Pasos: 11 | Recompensa: -1.00 | Promedio (últimos 100): -1.00 | Epsilon: 0.2621\n",
            "Evaluación: Meta no alcanzada.\n",
            "Ep: 1000/4000 | Pasos: 9 | Recompensa: -1.00 | Promedio (últimos 100): -1.00 | Epsilon: 0.2582\n",
            "Evaluación: Meta no alcanzada.\n",
            "Ep: 1100/4000 | Pasos: 36 | Recompensa: -1.00 | Promedio (últimos 100): -1.00 | Epsilon: 0.2543\n",
            "Evaluación: Meta no alcanzada.\n",
            "Ep: 1200/4000 | Pasos: 1 | Recompensa: -1.00 | Promedio (últimos 100): -1.00 | Epsilon: 0.2505\n",
            "Evaluación: Meta no alcanzada.\n",
            "Ep: 1300/4000 | Pasos: 24 | Recompensa: -1.00 | Promedio (últimos 100): -1.00 | Epsilon: 0.2468\n",
            "Evaluación: Meta no alcanzada.\n",
            "Ep: 1400/4000 | Pasos: 7 | Recompensa: -1.00 | Promedio (últimos 100): -1.00 | Epsilon: 0.2431\n",
            "Evaluación: Meta no alcanzada.\n",
            "Ep: 1500/4000 | Pasos: 12 | Recompensa: -1.00 | Promedio (últimos 100): -1.00 | Epsilon: 0.2395\n",
            "Evaluación: Meta no alcanzada.\n",
            "Ep: 1600/4000 | Pasos: 7 | Recompensa: -1.00 | Promedio (últimos 100): -1.00 | Epsilon: 0.2359\n",
            "Evaluación: Meta no alcanzada.\n",
            "Ep: 1700/4000 | Pasos: 43 | Recompensa: -1.00 | Promedio (últimos 100): -1.00 | Epsilon: 0.2324\n",
            "Evaluación: Meta no alcanzada.\n",
            "Ep: 1800/4000 | Pasos: 7 | Recompensa: -1.00 | Promedio (últimos 100): -1.00 | Epsilon: 0.2289\n",
            "Evaluación: Meta no alcanzada.\n",
            "Ep: 1900/4000 | Pasos: 1 | Recompensa: -1.00 | Promedio (últimos 100): -1.00 | Epsilon: 0.2255\n",
            "Evaluación: Meta no alcanzada.\n",
            "Ep: 2000/4000 | Pasos: 2 | Recompensa: -1.00 | Promedio (últimos 100): -1.00 | Epsilon: 0.2221\n",
            "Evaluación: Meta no alcanzada.\n",
            "Ep: 2100/4000 | Pasos: 40 | Recompensa: -1.00 | Promedio (últimos 100): -1.00 | Epsilon: 0.2188\n",
            "Evaluación: Meta no alcanzada.\n",
            "Ep: 2200/4000 | Pasos: 59 | Recompensa: -1.00 | Promedio (últimos 100): -1.00 | Epsilon: 0.2156\n",
            "Evaluación: Meta no alcanzada.\n",
            "Ep: 2300/4000 | Pasos: 34 | Recompensa: -1.00 | Promedio (últimos 100): -1.00 | Epsilon: 0.2124\n",
            "Evaluación: Meta no alcanzada.\n",
            "Ep: 2400/4000 | Pasos: 11 | Recompensa: -1.00 | Promedio (últimos 100): -1.00 | Epsilon: 0.2092\n",
            "Evaluación: Meta no alcanzada.\n",
            "Ep: 2500/4000 | Pasos: 1 | Recompensa: -1.00 | Promedio (últimos 100): -1.00 | Epsilon: 0.2061\n",
            "Evaluación: Meta no alcanzada.\n",
            "Ep: 2600/4000 | Pasos: 61 | Recompensa: -1.00 | Promedio (últimos 100): -1.00 | Epsilon: 0.2030\n",
            "Evaluación: Meta no alcanzada.\n",
            "Ep: 2700/4000 | Pasos: 4 | Recompensa: -1.00 | Promedio (últimos 100): -1.00 | Epsilon: 0.2000\n",
            "Evaluación: Meta no alcanzada.\n",
            "Ep: 2800/4000 | Pasos: 2 | Recompensa: -1.00 | Promedio (últimos 100): -1.00 | Epsilon: 0.1970\n",
            "Evaluación: Meta no alcanzada.\n",
            "Ep: 2900/4000 | Pasos: 5 | Recompensa: -1.00 | Promedio (últimos 100): -1.00 | Epsilon: 0.1941\n",
            "Evaluación: Meta no alcanzada.\n",
            "Ep: 3000/4000 | Pasos: 33 | Recompensa: -1.00 | Promedio (últimos 100): -1.00 | Epsilon: 0.1912\n",
            "Evaluación: Meta no alcanzada.\n",
            "Ep: 3100/4000 | Pasos: 8 | Recompensa: -1.00 | Promedio (últimos 100): -1.00 | Epsilon: 0.1883\n",
            "Evaluación: Meta no alcanzada.\n",
            "Ep: 3200/4000 | Pasos: 5 | Recompensa: -1.00 | Promedio (últimos 100): -1.00 | Epsilon: 0.1855\n",
            "Evaluación: Meta no alcanzada.\n",
            "Ep: 3300/4000 | Pasos: 64 | Recompensa: -1.00 | Promedio (últimos 100): -1.00 | Epsilon: 0.1827\n",
            "Evaluación: Meta no alcanzada.\n",
            "Ep: 3400/4000 | Pasos: 6 | Recompensa: -1.00 | Promedio (últimos 100): -1.00 | Epsilon: 0.1800\n",
            "Evaluación: Meta no alcanzada.\n",
            "Ep: 3500/4000 | Pasos: 8 | Recompensa: -1.00 | Promedio (últimos 100): -1.00 | Epsilon: 0.1773\n",
            "Evaluación: Meta no alcanzada.\n",
            "Ep: 3600/4000 | Pasos: 2 | Recompensa: -1.00 | Promedio (últimos 100): -1.00 | Epsilon: 0.1747\n",
            "Evaluación: Meta no alcanzada.\n",
            "Ep: 3700/4000 | Pasos: 12 | Recompensa: -1.00 | Promedio (últimos 100): -1.00 | Epsilon: 0.1721\n",
            "Evaluación: Meta no alcanzada.\n",
            "Ep: 3800/4000 | Pasos: 13 | Recompensa: -1.00 | Promedio (últimos 100): -1.00 | Epsilon: 0.1695\n",
            "Evaluación: Meta no alcanzada.\n",
            "Ep: 3900/4000 | Pasos: 9 | Recompensa: -1.00 | Promedio (últimos 100): -1.00 | Epsilon: 0.1670\n",
            "Evaluación: Meta no alcanzada.\n",
            "Ep: 4000/4000 | Pasos: 8 | Recompensa: -1.00 | Promedio (últimos 100): -1.00 | Epsilon: 0.1645\n",
            "Evaluación: Meta no alcanzada.\n",
            "\n",
            "--- Entrenamiento finalizado en 2.08 segundos ---\n",
            "No se encontró ninguna política que alcance la meta durante el entrenamiento.\n",
            "\n",
            "SARSA Final Policy:\n",
            "[ ^  x  ^  ^  ^  x  ^  ^  ^ \n",
            " ^  x  ^  x  ^  x  ^  x  ^ \n",
            " ^  x  ^  x  ^  x  ^  x  ^ \n",
            " ^  x  ^  x  ^  x  ^  x  ^ \n",
            " ^  x  ^  x  ^  x  ^  x  ^ \n",
            " ^  x  ^  x  ^  x  ^  x  ^ \n",
            " ^  x  ^  x  ^  x  ^  x  ^ \n",
            " ^  x  ^  x  ^  x  ^  x  ^ \n",
            " ^  V  ^  x  ^  ^  ^  x  x ]\n",
            "\n",
            "SARSA did not definitively converge to a goal policy.\n",
            "\n",
            "========================================\n",
            "RUNNING NEW Q-LEARNING IMPLEMENTATION\n",
            "========================================\n",
            "Configuración del aprendiz: {'learning_rate': 0.15, 'discount_factor': 0.98, 'initial_epsilon': 0.3, 'epsilon_decay': 0.997, 'min_epsilon': 0.02, 'epsilon_decay_interval': 20, 'num_episodes': 4000, 'max_steps_per_episode': 243, 'seed': 420, 'update_rule': 'q_learning', 'verbose': False, 'eval_interval': 100, 'initial_state': (0, 0)}\n",
            "\n",
            "--- Iniciando Entrenamiento (q_learning) ---\n",
            "Ep: 100/4000 | Pasos: 13 | Recompensa: -1.00 | Promedio (últimos 100): -1.00 | Epsilon: 0.2955\n",
            "Evaluación: Meta no alcanzada.\n",
            "Ep: 200/4000 | Pasos: 19 | Recompensa: -1.00 | Promedio (últimos 100): -1.00 | Epsilon: 0.2911\n",
            "Evaluación: Meta no alcanzada.\n",
            "Ep: 300/4000 | Pasos: 29 | Recompensa: -1.00 | Promedio (últimos 100): -1.00 | Epsilon: 0.2868\n",
            "Evaluación: Meta no alcanzada.\n",
            "Ep: 400/4000 | Pasos: 6 | Recompensa: -1.00 | Promedio (últimos 100): -1.00 | Epsilon: 0.2825\n",
            "Evaluación: Meta no alcanzada.\n",
            "Ep: 500/4000 | Pasos: 62 | Recompensa: -1.00 | Promedio (últimos 100): -1.00 | Epsilon: 0.2783\n",
            "Evaluación: Meta no alcanzada.\n",
            "Ep: 600/4000 | Pasos: 22 | Recompensa: -1.00 | Promedio (últimos 100): -1.00 | Epsilon: 0.2741\n",
            "Evaluación: Meta no alcanzada.\n",
            "Ep: 700/4000 | Pasos: 61 | Recompensa: -1.00 | Promedio (últimos 100): -1.00 | Epsilon: 0.2701\n",
            "Evaluación: Meta no alcanzada.\n",
            "Ep: 800/4000 | Pasos: 37 | Recompensa: -1.00 | Promedio (últimos 100): -1.00 | Epsilon: 0.2660\n",
            "Evaluación: Meta no alcanzada.\n",
            "Ep: 900/4000 | Pasos: 11 | Recompensa: -1.00 | Promedio (últimos 100): -1.00 | Epsilon: 0.2621\n",
            "Evaluación: Meta no alcanzada.\n",
            "Ep: 1000/4000 | Pasos: 9 | Recompensa: -1.00 | Promedio (últimos 100): -1.00 | Epsilon: 0.2582\n",
            "Evaluación: Meta no alcanzada.\n",
            "Ep: 1100/4000 | Pasos: 36 | Recompensa: -1.00 | Promedio (últimos 100): -1.00 | Epsilon: 0.2543\n",
            "Evaluación: Meta no alcanzada.\n",
            "Ep: 1200/4000 | Pasos: 1 | Recompensa: -1.00 | Promedio (últimos 100): -1.00 | Epsilon: 0.2505\n",
            "Evaluación: Meta no alcanzada.\n",
            "Ep: 1300/4000 | Pasos: 24 | Recompensa: -1.00 | Promedio (últimos 100): -1.00 | Epsilon: 0.2468\n",
            "Evaluación: Meta no alcanzada.\n",
            "Ep: 1400/4000 | Pasos: 7 | Recompensa: -1.00 | Promedio (últimos 100): -1.00 | Epsilon: 0.2431\n",
            "Evaluación: Meta no alcanzada.\n",
            "Ep: 1500/4000 | Pasos: 12 | Recompensa: -1.00 | Promedio (últimos 100): -1.00 | Epsilon: 0.2395\n",
            "Evaluación: Meta no alcanzada.\n",
            "Ep: 1600/4000 | Pasos: 7 | Recompensa: -1.00 | Promedio (últimos 100): -1.00 | Epsilon: 0.2359\n",
            "Evaluación: Meta no alcanzada.\n",
            "Ep: 1700/4000 | Pasos: 43 | Recompensa: -1.00 | Promedio (últimos 100): -1.00 | Epsilon: 0.2324\n",
            "Evaluación: Meta no alcanzada.\n",
            "Ep: 1800/4000 | Pasos: 7 | Recompensa: -1.00 | Promedio (últimos 100): -1.00 | Epsilon: 0.2289\n",
            "Evaluación: Meta no alcanzada.\n",
            "Ep: 1900/4000 | Pasos: 1 | Recompensa: -1.00 | Promedio (últimos 100): -1.00 | Epsilon: 0.2255\n",
            "Evaluación: Meta no alcanzada.\n",
            "Ep: 2000/4000 | Pasos: 2 | Recompensa: -1.00 | Promedio (últimos 100): -1.00 | Epsilon: 0.2221\n",
            "Evaluación: Meta no alcanzada.\n",
            "Ep: 2100/4000 | Pasos: 40 | Recompensa: -1.00 | Promedio (últimos 100): -1.00 | Epsilon: 0.2188\n",
            "Evaluación: Meta no alcanzada.\n",
            "Ep: 2200/4000 | Pasos: 59 | Recompensa: -1.00 | Promedio (últimos 100): -1.00 | Epsilon: 0.2156\n",
            "Evaluación: Meta no alcanzada.\n",
            "Ep: 2300/4000 | Pasos: 34 | Recompensa: -1.00 | Promedio (últimos 100): -1.00 | Epsilon: 0.2124\n",
            "Evaluación: Meta no alcanzada.\n",
            "Ep: 2400/4000 | Pasos: 11 | Recompensa: -1.00 | Promedio (últimos 100): -1.00 | Epsilon: 0.2092\n",
            "Evaluación: Meta no alcanzada.\n",
            "Ep: 2500/4000 | Pasos: 1 | Recompensa: -1.00 | Promedio (últimos 100): -1.00 | Epsilon: 0.2061\n",
            "Evaluación: Meta no alcanzada.\n",
            "Ep: 2600/4000 | Pasos: 61 | Recompensa: -1.00 | Promedio (últimos 100): -1.00 | Epsilon: 0.2030\n",
            "Evaluación: Meta no alcanzada.\n",
            "Ep: 2700/4000 | Pasos: 4 | Recompensa: -1.00 | Promedio (últimos 100): -1.00 | Epsilon: 0.2000\n",
            "Evaluación: Meta no alcanzada.\n",
            "Ep: 2800/4000 | Pasos: 2 | Recompensa: -1.00 | Promedio (últimos 100): -1.00 | Epsilon: 0.1970\n",
            "Evaluación: Meta no alcanzada.\n",
            "Ep: 2900/4000 | Pasos: 5 | Recompensa: -1.00 | Promedio (últimos 100): -1.00 | Epsilon: 0.1941\n",
            "Evaluación: Meta no alcanzada.\n",
            "Ep: 3000/4000 | Pasos: 33 | Recompensa: -1.00 | Promedio (últimos 100): -1.00 | Epsilon: 0.1912\n",
            "Evaluación: Meta no alcanzada.\n",
            "Ep: 3100/4000 | Pasos: 8 | Recompensa: -1.00 | Promedio (últimos 100): -1.00 | Epsilon: 0.1883\n",
            "Evaluación: Meta no alcanzada.\n",
            "Ep: 3200/4000 | Pasos: 5 | Recompensa: -1.00 | Promedio (últimos 100): -1.00 | Epsilon: 0.1855\n",
            "Evaluación: Meta no alcanzada.\n",
            "Ep: 3300/4000 | Pasos: 64 | Recompensa: -1.00 | Promedio (últimos 100): -1.00 | Epsilon: 0.1827\n",
            "Evaluación: Meta no alcanzada.\n",
            "Ep: 3400/4000 | Pasos: 6 | Recompensa: -1.00 | Promedio (últimos 100): -1.00 | Epsilon: 0.1800\n",
            "Evaluación: Meta no alcanzada.\n",
            "Ep: 3500/4000 | Pasos: 8 | Recompensa: -1.00 | Promedio (últimos 100): -1.00 | Epsilon: 0.1773\n",
            "Evaluación: Meta no alcanzada.\n",
            "Ep: 3600/4000 | Pasos: 2 | Recompensa: -1.00 | Promedio (últimos 100): -1.00 | Epsilon: 0.1747\n",
            "Evaluación: Meta no alcanzada.\n",
            "Ep: 3700/4000 | Pasos: 12 | Recompensa: -1.00 | Promedio (últimos 100): -1.00 | Epsilon: 0.1721\n",
            "Evaluación: Meta no alcanzada.\n",
            "Ep: 3800/4000 | Pasos: 13 | Recompensa: -1.00 | Promedio (últimos 100): -1.00 | Epsilon: 0.1695\n",
            "Evaluación: Meta no alcanzada.\n",
            "Ep: 3900/4000 | Pasos: 9 | Recompensa: -1.00 | Promedio (últimos 100): -1.00 | Epsilon: 0.1670\n",
            "Evaluación: Meta no alcanzada.\n",
            "Ep: 4000/4000 | Pasos: 8 | Recompensa: -1.00 | Promedio (últimos 100): -1.00 | Epsilon: 0.1645\n",
            "Evaluación: Meta no alcanzada.\n",
            "\n",
            "--- Entrenamiento finalizado en 2.07 segundos ---\n",
            "No se encontró ninguna política que alcance la meta durante el entrenamiento.\n",
            "\n",
            "Q-Learning Final Policy:\n",
            "[ ^  x  ^  ^  ^  x  ^  ^  ^ \n",
            " ^  x  ^  x  ^  x  ^  x  ^ \n",
            " ^  x  ^  x  ^  x  ^  x  ^ \n",
            " ^  x  ^  x  ^  x  ^  x  ^ \n",
            " ^  x  ^  x  ^  x  ^  x  ^ \n",
            " ^  x  ^  x  ^  x  ^  x  ^ \n",
            " ^  x  ^  x  ^  x  ^  x  ^ \n",
            " ^  x  ^  x  ^  x  ^  x  ^ \n",
            " ^  V  ^  x  ^  ^  ^  x  x ]\n",
            "\n",
            "Q-Learning did not definitively converge to a goal policy.\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABKMAAAJOCAYAAABr8MR3AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAB1L0lEQVR4nO3de3zP9f//8ft7dp6NMTZzPuWQ44fCyHkORSSnSESSPpJUDqXMJ+WQpJKOikpSSUklU4iYQyGnfOWYGMVsQ2a25+8Pv715e2/szfba9n7frpfLLhfv1/v1er2fj9frPe/H7u/XwWaMMQIAAAAAAAAs4JXXAwAAAAAAAIDnIIwCAAAAAACAZQijAAAAAAAAYBnCKAAAAAAAAFiGMAoAAAAAAACWIYwCAAAAAACAZQijAAAAAAAAYBnCKAAAAAAAAFiGMAoAAAAAAACWIYyC21u/fr3uuusulStXTn5+fgoPD1eTJk30+OOPZ7nMyJEjZbPZ1KlTp0yfP3DggGw2m/3Hy8tLoaGhatOmjZYtW5bpMt9//73atWunyMhI+fn5KTIyUi1bttTkyZOzHEe3bt1ks9k0bNgwl2rOGFdm654zZ45sNps2bdrk0jrz2uXb+8qfAQMGXNc6K1SocN3LXq+M7X/gwIEcWd/KlSsdtkWhQoVUokQJde7cucDt46tp2bKlWrZsmWPrW716tfz8/HTw4EGH17DZbKpUqZKMMU7L/PTTT/btPGfOnEzX++qrr8pms6lWrVqZPp+QkKCiRYvqyy+/zIkyACBLcXFx6tGjh0qVKiVfX1+VKlVKPXv21MaNG11aT8uWLbP8Py0/y+jVsvr/2orXttls+uSTT5yej4mJkc1m0z///GP52K7Xlb3vlT8xMTHXtd4bWfZ6ZWz/nJLR22X8eHt7q1SpUurdu7f27NmTY6+T13K6b/7ggw9UokQJJScnO7yGzWbLsuf74IMP7Nt55cqVmc5zrb/j/u///k++vr769ddfb7QE3CDCKLi1b775RlFRUUpKStLUqVO1bNkyvfLKK2ratKkWLFiQ6TKpqan66KOPJElLly7VX3/9leX6H3nkEa1bt06rV6/WtGnTtGfPHt1+++366aefHOZ788031aFDB4WEhGjmzJn6/vvvNWXKFNWoUUOff/55pus+fvy4lixZIkmaN2+ezp0753L9kydP1smTJ11eLr/q3r271q1b5/TzzDPPXNf6Fi1adN3L5jcvvPCC1q1bp5UrV+qZZ57R2rVr1aJFC7dqgnKKMUYjRozQ4MGDVb58eYfngoODtX//fv34449Oy7333nsKCQm56rrfe+89SdKOHTu0fv16p+dDQ0P12GOP6cknn9T58+dvoAoAyNprr72mpk2b6vDhw5o6daqWL1+uF198UX/++acaN26st99+O6+HmOtKlSqldevW6Y477sjTcTz99NNKTU3N0zHkpIze98qfBx544LrWdyPL5jfvv/++1q1bp+XLl2vYsGFavHixmjVrpoSEhLweWr5z9uxZPfXUUxo9erSCg4MdngsODtZPP/2kvXv3Oi13rV4sO3/H3XTTTerbt68ee+yxG6wCN8wAbqx58+amcuXKJjU11em5tLS0TJf57LPPjCRzxx13GEnm+eefd5pn//79RpJ58cUXHaavWrXKSDL33Xefw/Ry5cqZ5s2bZ/p6WY3jxRdfdBjHvHnzMp0vM5JM27Ztjbe3txk5cqTDc++//76RZDZu3Jjt9eUHksx///vfvB7GDcvY/vv378+R9a1YscJIMp999pnD9Llz5xpJ5tlnn82R18ltZ8+eNenp6Vk+36JFC9OiRYscea1vv/3WSDK///6702vcfPPNpnHjxqZPnz4OzyUlJZnAwEAzePBgI8m8//77TuvduHGjw+/s4MGDM339+Ph44+3t7dLvNABk15o1a4yXl5fp1KmTU/+TmppqOnXqZAoVKmQ2bNiQrfVl/N+Y1671OZGfZPSJHTt2NJLMq6++6vD8+PHjjSTz999/59EIXZdV71sQZWz/nJJVbz1hwgQjybz33ns59lq56cyZM1d9vnz58qZ///458lqzZs0y/v7+JiEhwek1OnbsaMqUKWOeeuoph+f++OMPY7PZ7L3YihUrnNabnb/jjDFm06ZNRpL5+eefc6QeXB+OjIJbO3HihMLCwuTt7e30nJdX5m//2bNny9fXV++//77Kli2r999/P9NTdjLTsGFDSdKxY8ecxlGqVKlMl8lqHO+9957Cw8M1d+5cBQQE2I+4yK5q1app0KBBev311x1ORcrKpk2bdOedd6pYsWLy9/dX/fr19emnn9qfT0pKkre3t1588UX7tH/++UdeXl4qUqSILly4YJ8+fPhwlShRItvbLScNGDBAhQsX1o4dO9SmTRsFBQWpRIkSGjZsmM6ePesw75WHG6enp2vixImqVq2aAgICVLRoUdWpU0evvPKKw3Jr1qxRmzZtFBwcrMDAQEVFRembb75xGktcXJyaNm0qf39/RUZGauzYsVl+O7pgwQI1adJEQUFBKly4sNq3b6/Nmzdf93bI6r24Z88e9enTRyVLlpSfn59q1Kih119/3f68MUbh4eH673//a5+Wlpam0NBQeXl5Oaxv+vTp8vb21qlTpyRdfA/17t1bFSpUUEBAgCpUqKB77rnH6f2XcTj7smXLNHDgQJUoUUKBgYFKSUmRMUZTp05V+fLl5e/vr//85z/67rvvnOrL7r7KzBtvvKFbbrlF1apVy/T5gQMH6osvvrDXJcl+mkXv3r2zXO/s2bMlXTwiMSoqSp988onTe06SwsPDFR0drTfffPOaYwUAV02aNEk2m01vvPGGU//j7e2tWbNm2efLSdn5HMuJz4mM0wY3btyo2267TYGBgapUqZImT56s9PR0+zoyO00v4/SsHTt26J577lGRIkUUHh6ugQMHKjEx0WEMp06d0qBBg1SsWDEVLlxYd9xxh/bt2+fSaWWtW7dW+/bt9dxzzzmcipSV5cuXq02bNgoJCVFgYKCaNm2qH374wf78jh07ZLPZ9Nlnn9mn/fLLL7LZbLr55psd1nXnnXeqQYMG2RpnTsvYR6tXr1bjxo0VEBCg0qVL65lnnlFaWprDvFduz7Nnz+qJJ55QxYoV5e/vr2LFiqlhw4aaP3++w3KLFy9WkyZNFBgYqODgYEVHR2vdunVOY/nmm29Ur149+fn5qWLFipo2bVqmYzbGaNasWapXr54CAgIUGhqq7t27a9++fde9HbLqxXKz546NjVWXLl1UpkwZ+fv7q0qVKhoyZIjTKaEZvwu//vqrunfvrtDQUFWuXFnSxaOLRo0apYiICAUGBqpZs2basGGDU33Z3VeZeeONN9S5c2cVLVrU6TkvLy/dd999mjt3rsPv9HvvvaeyZcuqbdu2Wa43u3/HNWjQQDVq1KAXy2OEUXBrTZo00fr16zV8+HCtX7/+modJHz58WMuWLVOXLl1UokQJ9e/fX3/88YfTaXdZ2b9/v6SLh39eOY6FCxcqJiZGW7dudfogvtLatWu1a9cu3XfffSpevLjuvvtu/fjjj/b1Z1dMTIwKFSp0zVPRVqxYoaZNm+rUqVN688039dVXX6levXrq1auXvYkLCQnRLbfcouXLl9uX++GHH+Tn56fk5GSHD6nly5erdevWOXo+vnSxUbhw4YLTz5UfMqmpqbr99tvVpk0bffnllxo2bJjeeust9erV66rrnzp1qmJiYnTPPffom2++0YIFCzRo0CCHUGLVqlVq3bq1EhMTNXv2bM2fP1/BwcHq3Lmzw6mfO3fuVJs2bXTq1CnNmTNHb775pjZv3qyJEyc6ve4LL7yge+65RzVr1tSnn36qDz/8UMnJybrtttu0c+fO69pWmb0Xd+7cqVtuuUXbt2/XSy+9pCVLluiOO+7Q8OHDNWHCBEkXm8LWrVs77OdNmzbp1KlT8vf3d2iKly9frgYNGtgbiQMHDqhatWqaMWOG/VTUo0eP6pZbbsn0uhgDBw6Uj4+PPvzwQ33++efy8fHRhAkTNHr0aEVHR+vLL7/U0KFDNXjwYO3evdth2ezsq8ycP39ey5cvV6tWrbKcp3fv3ipUqJBDMzV79mx17949y0PD//33X82fP1+33HKLatWqpYEDByo5OdnhD4bLtWzZUj///PM1xwsArkhLS9OKFSvUsGFDlSlTJtN5ypYtqwYNGmj58uUOf+jdiOx+juXE54QkxcfHq2/fvrr33nu1ePFidezYUWPHjrWfnnMtd999t2666SYtXLhQY8aM0ccff+xwyk56ero6d+6sjz/+WKNHj9aiRYvUqFEjdejQweVtM2XKFP3zzz8OwUJmPvroI7Vr104hISGaO3euPv30UxUrVkzt27e3f/befPPNKlWqlMNn9PLlyxUQEKCdO3fqyJEjkqQLFy5o1apVV/2j/Xqlp6dn2otdKT4+Xr1791bfvn311VdfqXv37po4caIeffTRq65/5MiReuONNzR8+HAtXbpUH374oXr06KETJ07Y5/n444/VpUsXhYSEaP78+Zo9e7YSEhLUsmVLrVmzxj7fDz/8oC5duig4OFiffPKJXnzxRX366ad6//33nV53yJAhGjFihNq2basvv/xSs2bN0o4dOxQVFeUUJmVXZr1Ybvfce/fuVZMmTfTGG29o2bJlevbZZ7V+/Xo1a9Ys07+DunXrpipVquizzz6zBzODBw/WtGnTdN999+mrr77S3XffrW7dujmdbpidfZWZw4cPa9u2bVftxQYOHKgjR47o+++/l3Tx/7a5c+dqwIABWX6R7+rfcS1bttR3332XJ1+e4//Lq0OyACv8888/plmzZkaSkWR8fHxMVFSUmTRpkklOTnaa/3//+5+RZJYuXWqMMWbfvn3GZrOZfv36OcyXcajylClTTGpqqjl37pzZsmWLadKkiSlVqpTTKVh//PGHqVWrln0cAQEBpk2bNmbmzJnm/PnzTuMYOHCgkWR27dpljLl0KtYzzzyTrbp12SltTz/9tPHy8jJbt241xmR+KHH16tVN/fr1nQ7n79SpkylVqpT9VMJx48aZgIAAc+7cOWOMMQ888IDp0KGDqVOnjpkwYYIxxpi//vrLSDJvv/12tsaaXRnbLrOfDz/80D5f//79jSTzyiuvOCz//PPPG0lmzZo19mlXHm7cqVMnU69evauOo3HjxqZkyZIO758LFy6YWrVqmTJlythPIejVq5cJCAgw8fHxDvNVr17d4TS9Q4cOGW9vb/PII484vE5ycrKJiIgwPXv2vOp4Mt4bCxYsMKmpqebs2bPm559/NtWqVTM1a9Z0OPy5ffv2pkyZMiYxMdFhHcOGDTP+/v7m5MmTxhhj3n33XSPJHDp0yBhjzMSJE0316tXNnXfeae6//35jjDHnz583QUFBTodQX+7ChQvm9OnTJigoyGF/ZLwHrzydNSEhwfj7+5u77rrLYfrPP/9sJDmcppedfZWZ9evXG0nmk08+cXru8lNR+vfvbxo2bGiMMWbHjh1Gklm5cqX9VLwrT9P74IMPjCTz5ptvGmMu7r/ChQub2267LdNxxMbGGknmu+++c7kGAMhKfHy8kWR69+591fl69eqV7dPErnWa3o18jrn6OZExHklm/fr1DtNr1qxp2rdvb3+c0atd/v91xulZU6dOdVj24YcfNv7+/vbP8G+++cZIMm+88YbDfJMmTTKSzPjx47Os6fLXzjilrW/fviYoKMgcPXrUYRwZ2//MmTOmWLFipnPnzg7rSUtLM3Xr1jW33nqrfdq9995rKlWqZH/ctm1bM3jwYBMaGmrmzp1rjLn0ubls2bKrjtMVGTVl9bN69Wr7vBn76KuvvnJYx+DBg42Xl5c5ePCgfdqV27NWrVqma9euWY4jLS3NREZGmtq1aztc6iI5OdmULFnSREVF2ac1atTIREZGmn///dc+LSkpyRQrVszhNL1169YZSeall15yeK0///zTBAQEmFGjRl1122S8X+Pi4kxqaqpJTk42S5cuNREREaZ58+YO/bWVPXd6erpJTU01Bw8edNofGe/BKy/nsGvXLiPJPPbYYw7T582bZyQ59M3X2ldZWbBggX17Xal8+fLmjjvuMMZcfB91797dGHPxd9Jms5n9+/fbT8W78jS97P4dl+Gdd95x+HsL1uPIKLi14sWLa/Xq1dq4caMmT56sLl266P/+7/80duxY1a5d2+FbOGOM/ZDO6OhoSVLFihXVsmVLLVy4UElJSU7rHz16tHx8fOTv76969epp+/bt+vrrr1WhQgWH+SpXrqytW7dq1apVmjBhgtq2bauNGzdq2LBhatKkicPFyU+fPq1PP/1UUVFRql69uiSpRYsWqly5subMmePyt5ijRo1SsWLFNHr06Eyf/+OPP/T777+rb9++kuTwLdftt9+uo0eP2o9KadOmjf7991+tXbtW0sVvY6Kjo9W2bVvFxsbap0m65rdx1zq6KTMZdwG68uf22293mjejngx9+vSRdPEbqazceuut2rp1qx5++GF9//33Tvv8zJkzWr9+vbp3767ChQvbpxcqVEj9+vXT4cOH7dtqxYoVatOmjcLDwx3mu/LorO+//14XLlzQfffd57A9/P391aJFiyzvFHKlXr16ycfHx35Yf1JSkr755hv7UUvnzp3TDz/8oLvuukuBgYFO+/ncuXOKi4uTdGnfZezL2NhYp/28bt06nTlzxmE/nz59WqNHj1aVKlXk7e0tb29vFS5cWGfOnNGuXbucxnz33Xc7PF63bp3OnTvntO+ioqKcLjR+rX2VlYxvjUuWLHnV+QYOHKhNmzZp27Ztmj17tipXrqzmzZtnOf/s2bMVEBBgP42vcOHC6tGjh1avXp3pReQzXv9qN0gAgNyS8ZmbcTTFlUe7XOsI7su58jl2o58TGSIiInTrrbc6TKtTp062LksgXTyF7cplz507p+PHj0u6eBS0dLHvuNw999yTrfVfaeLEiUpNTbUfhXyltWvX6uTJk+rfv7/DNkxPT1eHDh20ceNGnTlzRtLFXmzfvn3av3+/zp07pzVr1qhDhw5q1aqVQy/m5+enZs2aZTkmk8nR5tnx6KOPZtqL1atXz2G+4OBgp+3cp08fpaenX/WMg1tvvVXfffedxowZo5UrV+rff/91eH737t06cuSI+vXr53CETOHChXX33XcrLi5OZ8+e1ZkzZ7Rx40Z169ZN/v7+DuPq3LmzwzqXLFkim82me++912F7REREqG7dutnuxRo3biwfHx8FBwerQ4cOCg0N1VdffWU/XdaKnvv48eN66KGHVLZsWXl7e8vHx8feQ2XndyyjT76yF+vZs6fTab/X2ldZcaUXW7x4sU6cOKHZs2erVatWTn9jZbiev+PoxfIeYRQ8QsOGDTV69Gh99tlnOnLkiB577DEdOHBAU6dOtc+TcRpcjx49lJSUpFOnTunUqVPq2bOnzp49m+n5zxkfyGvWrNG0adOUmpqqLl26ZHp4qpeXl5o3b65nn31Wixcv1pEjR9SrVy/98ssvDteDWrBggU6fPq2ePXvax5CYmKiePXvqzz//tH8AZVdISIjGjRunpUuXZhrEZBx6/MQTT8jHx8fh5+GHH5Yke2gXFRWlwMBALV++XH/88YcOHDhg/2Bcv369Tp8+reXLl6tSpUqqWLFilmM6cOCA02tlNH5XU6JECTVs2NDpp1ixYg7zeXt7q3jx4g7TIiIiJOmqhw6PHTtW06ZNU1xcnDp27KjixYurTZs22rRpkyQpISFBxphMr/8VGRnpsP4TJ07YXzOzcWTI2P633HKL0zZZsGBBtm/7PGXKFG3cuFGrVq3S008/rWPHjqlr165KSUmxj+fChQt67bXXnF4nI8zLeK3y5curcuXKWr58uc6ePat169bZ93NG4JZxWkBUVJR9DH369NHMmTP1wAMP6Pvvv9eGDRu0ceNGlShRItMG5crtmLHtsrPdrrWvspIxjssb08w0b95cVatW1VtvvaUPP/xQAwcOzPK004xDwO+44w4ZY+y/t927d5ekTK/3lvH62W3cACA7wsLCFBgYeM3T+g8cOKCAgAD7Z2XG6XAZP23atMn2a7ryOXajnxMZrvyMlyQ/P79s/5965fJ+fn6SLv2ffOLECXl7ezv1F5d/weSKChUq6OGHH9a7776b6RcUGduwe/fuTttwypQpMsbY7458+RdGa9asUWpqqlq3bq22bdvaT+dbvny5mjZtqoCAgCzHtGrVKqfXOnDgwDVrKVOmTKa92OVf0kmZb6vs9GKvvvqqRo8erS+//FKtWrVSsWLF1LVrV/t2y1g2q14sPT1dCQkJSkhIUHp6erZ7MfP/r5l55TaJi4vLdi/2wQcfaOPGjfrxxx81ZMgQ7dq1yyHAzO2eOz09Xe3atdMXX3yhUaNG6YcfftCGDRvsXzbeSC+WWW99rX2Vlez2Yt27d5e/v79efvllff311xo0aFCW817P33H0YnnP+arOgJvz8fHR+PHj9fLLL2v79u326RkXH54+fbqmT5/utNzs2bM1ZMgQh2kZH8iS1LRpU0VEROjee+/V+PHjNXPmzKuOIygoSGPHjtWCBQsyHceIESM0YsSITMfRvn377BX7/w0dOlSvvPKKRo8eraFDhzo8FxYWJuniH/fdunXLdPmMCz37+vqqWbNmWr58ucqUKaOIiAjVrl1blSpVkiStXLlSP/zwgzp16nTV8URGRmrjxo2ZvkZOuHDhgk6cOOHwoRkfHy8p8wY2g7e3t0aOHKmRI0fq1KlTWr58uZ566im1b99ef/75p/0i3kePHnVaNuNbnoztWbx4cftrXu7KaRnzf/75505H/7iiUqVK9vdi8+bNFRAQoHHjxum1117TE088odDQUPsRXJdfnPxylweIbdq00VdffaVVq1YpPT1dLVu2VHBwsCIjIxUbG6vly5frtttuszfwiYmJWrJkicaPH68xY8bY15OSkmJvoK90ZbiTsW+y2m6Xfxt2rX0VGBiY6WtmbO+sxnS5+++/X+PGjZPNZlP//v2znO+9996TMUaff/65Pv/8c6fn586dq4kTJ6pQoUL2aRmvnzEeAMgJhQoVUuvWrfXdd9/p8OHDmV436vDhw/rll18crn8UExOjYcOG2R9feav1q8nu51hOfE5YpXjx4rpw4YJOnjzpEEhl9vmUXePGjdN7772np556yuli4xnb8LXXXlPjxo0zXT4j3ClTpoxuuukmLV++XBUqVFDDhg1VtGhRtWnTRg8//LDWr1+vuLi4LI/CytCgQQOnXizji7WckNl1lrLTiwUFBWnChAmaMGGCjh07Zj/ypnPnzvr999/ty2bVi3l5eSk0NFTGGNlstmz3YjabTatXr7b3NZfLbFpmatSoYe/FWrVqpbS0NL377rv6/PPP1b1791zvubdv366tW7dqzpw5Dn3LH3/8keWYr9aLlS5d2j49o7e+3LX2VVYu78WyCpwlKTAwUL1799akSZMUEhKS5TaTru/vOHqxvEcYBbd29OjRTP+TyzhMNeNDNyEhQYsWLVLTpk0zvcD0u+++q3nz5mn79u2qVatWlq/Xt29fvfvuu3rnnXf05JNP2puy7I5j165dWrdune6++26HpjDDxIkT9dVXXzkFLdfi6+uriRMnqm/fvk7/4VarVk1Vq1bV1q1b9cILL1xzXW3bttXYsWMVHBxs/3YuKChIjRs31muvvaYjR45c8xQ9X19f+4d1bpk3b56GDx9uf/zxxx9LunixwuwoWrSounfvrr/++ksjRozQgQMHVLNmTTVq1EhffPGFpk2bZv/GMT09XR999JG9QZQuNiGLFy/WsWPH7A1kWlqaw0XOJal9+/by9vbW3r17szwd4XqMGjVKc+bM0eTJkzVkyBAFBwerVatW2rx5s+rUqSNfX9+rLt+2bVu9/fbbmjFjhho3bmz/w6RNmzZatGiRNm7c6PB+sdlsMsY4NWzvvvtutk/3aNy4sfz9/TVv3jyHbbF27VodPHgwy0Ozs9pXmalRo4akixf4vJb+/ftr/fr1qlGjhkNDdrmMC2pWrlxZ7777rtPzS5Ys0UsvvaTvvvvOoWHMuDtPVuMEgOs1ZswYffvtt3r44Ye1aNEihyA8LS1NQ4cOVVpamsOFpCtUqJDl/7HXkt3PsZz4nLBKixYtNHXqVC1YsMDhS7yMO6tej+LFi2v06NF6+umn7afcZWjatKmKFi2qnTt3Ztr/Xalt27b69NNPVbZsWd1xxx2SLl4ku1y5cnr22WeVmpp6zV4sODg4V3ux5ORkLV682OFUvY8//th+pkB2hIeHa8CAAdq6datmzJihs2fPqlq1aipdurQ+/vhjPfHEE/Yw5cyZM1q4cKH9DnvSxdPIvvjiC7344ov2o2CSk5P19ddfO7xOp06dNHnyZP31119Op2beiKlTp2rhwoV69tln1a1bt1zvuTO2xZW/Y2+99Va2x5zRJ8+bN8/hboyffvrpVU/lzGxfZfXFYMZlSPbu3esUzF5p6NChOnbsmFq0aJHlkVTX+3fcvn375OXllaNfiMM1hFFwa+3bt1eZMmXUuXNnVa9eXenp6dqyZYteeuklFS5c2N6IzZs3T+fOndPw4cMzDSuKFy+uefPmafbs2Xr55Zev+ppTpkxRo0aN9Nxzz9n/OL355pvVpk0bdezYUZUrV9a5c+e0fv16vfTSSwoPD7cfdpqR6o8aNcrpWgjSxQ/QH374QR999NE170ZypXvuuUfTpk3Td9995/TcW2+9pY4dO6p9+/YaMGCASpcurZMnT2rXrl369ddfHe4I1qZNG6WlpemHH37Q3Llz7dPbtm2r8ePH2+/GlhuOHTtmP9T4ciEhIQ5/1Pv6+uqll17S6dOndcstt2jt2rWaOHGiOnbseNXrJ3Tu3Fm1atVSw4YNVaJECR08eFAzZsxQ+fLlVbVqVUkXb4UdHR2tVq1a6YknnpCvr69mzZql7du3a/78+fZGYNy4cVq8eLFat26tZ599VoGBgXr99dedGtAKFSrof//7n55++mnt27fPfo2BY8eOacOGDfZvnVzl4+OjF154QT179tQrr7yicePG6ZVXXlGzZs102223aejQoapQoYKSk5P1xx9/6Ouvv9aPP/5oXz7jzizLli1zeP22bdvav227vAEKCQlR8+bN9eKLLyosLEwVKlTQqlWrNHv27Exv25uZ0NBQPfHEE5o4caIeeOAB9ejRQ3/++adiYmKcDhfPzr7KTJkyZVSpUiXFxcU5hJWZiYyM1JdffnnVeb777jsdOXJEU6ZMyfT/jlq1amnmzJmaPXu2QxgVFxen4sWLq3bt2lddPwC4qmnTppoxY4YeffRRNWvWTMOGDVO5cuV06NAhvf7661q3bp1iYmLs11XJjqSkpEyP/CxRooRatGiRrc+xnPicsEqHDh3UtGlTPf7440pKSlKDBg20bt06ffDBB5KU5d28rmXEiBF6/fXXnXqxwoUL67XXXlP//v118uRJde/eXSVLltTff/+trVu36u+//9Ybb7xhn79NmzaaNWuW/vnnH82YMcNh+vvvv6/Q0FCHICEnHTp0KNNerESJEqpcubL9cfHixTV06FAdOnRIN910k7799lu98847Gjp0qMqVK5fl+hs1aqROnTqpTp06Cg0N1a5du/Thhx86hExTp05V37591alTJw0ZMkQpKSl68cUXderUKU2ePNm+rueee04dOnRQdHS0Hn/8caWlpWnKlCkKCgpyOBqvadOmevDBB3X//fdr06ZNat68uYKCgnT06FGtWbNGtWvXdjqzIDtCQ0M1duxYjRo1Sh9//LHuvffeXO25q1evrsqVK2vMmDEyxqhYsWL6+uuvXbrER40aNXTvvfdqxowZ8vHxUdu2bbV9+3ZNmzbN6Y7C2dlXmWnUqJECAgIUFxfndF2xK9WrV++avdj1/h0XFxenevXqKTQ09KrrRy7Ki6umA1ZZsGCB6dOnj6lataopXLiw8fHxMeXKlTP9+vUzO3futM9Xr149U7JkSZOSkpLluho3bmzCwsJMSkqK011SrtSjRw/j7e1t/vjjD2OMMW+99Zbp1q2bqVSpkgkMDDS+vr6mcuXK5qGHHjJ//vmnMebi3clKlix51TuEXbhwwZQpU8bUrl37qnXrsrvpXW7ZsmX2u55cfjc9Y4zZunWr6dmzpylZsqTx8fExERERpnXr1va7g2VIT083YWFhRpL566+/7NMz7tzyn//856pju166yh1cmjZtap+vf//+JigoyPz222+mZcuWJiAgwBQrVswMHTrUnD592mGdV95N76WXXjJRUVEmLCzM+Pr6mnLlyplBgwaZAwcOOCy3evVq07p1axMUFGQCAgJM48aNzddff+005p9//tk0btzY+Pn5mYiICPPkk0+at99+2+Fuehm+/PJL06pVKxMSEmL8/PxM+fLlTffu3c3y5cuvul0y7qb32WefZfp8o0aNTGhoqDl16pQx5uLdcAYOHGhKly5tfHx8TIkSJUxUVJSZOHGi07L169c3kszPP/9sn5Zx55bixYvb7zqU4fDhw+buu+82oaGhJjg42HTo0MFs377daTtndkfHDOnp6WbSpEmmbNmyxtfX19SpU8d8/fXXpkWLFg5308vuvsrMM888Y0JDQ+13qMlwrTtGGWOc7qbXtWtX4+vra44fP57lMr179zbe3t72Oyump6eb8uXLO915CgBy0tq1a83dd99twsPDjZeXl5Fk/P39zTfffOPSejLujJbZz+X/L2fncywnPiey+r+6f//+pnz58vbHV7ub3pV3Ecx4vcs/m0+ePGnuv/9+U7RoURMYGGiio6NNXFxcpnfsvdLV+sSMPiCzcaxatcrccccdplixYsbHx8eULl3a3HHHHU6f8QkJCcbLy8sEBQU53JU5445n3bp1u+r4rse17qbXt29f+7wZ+2jlypWmYcOGxs/Pz5QqVco89dRTTneR0xV30xszZoxp2LChCQ0NNX5+fqZSpUrmscceM//884/Dcl9++aVp1KiR8ff3N0FBQaZNmzYO/UqGxYsXmzp16th7hcmTJ9vfB1d67733TKNGjez9XeXKlc19991nNm3adNVtc7X367///mvKlStnqlatai5cuGCMyd2ee+fOnSY6OtoEBweb0NBQ06NHD3Po0CGn7ZzV74IxxqSkpJjHH3/clCxZ0vj7+5vGjRubdevWOf2eZndfZaZfv36mZs2aTtMvv5teVq68m56rf8cZc/Hui4GBgU53UIS1bMZk4xZWAFBADBgwQJ9//rlOnz6d10NBPnXkyBFVrFhRH3zwgdPdDa3www8/qF27dtqxY4f9UHUAyG0ffPCB+vfvr1GjRmnKlCl5PZwC6eOPP1bfvn31888/O9zAA45atmypf/75x+GaqMDlNm3apFtuuUVxcXFq1KiR5a8/e/ZsPfroo/ZrwiJvcJoeAMCjREZGasSIEXr++efVo0eP6z7d4npNnDhRAwcOJIgCYKn77rtPR48e1ZgxYxQUFKRnn302r4eUr82fP19//fWXateuLS8vL8XFxenFF19U8+bNCaKAG9SwYUP17NlTzz33nJYsWWLpa1+4cEFTpkzR2LFjCaLyGGEUAMDjjBs3ToGBgfrrr79UtmxZy143ISFBLVq0sN/CGQCsNHr0aI0ePTqvh1EgBAcH65NPPtHEiRN15swZlSpVSgMGDMj0AskAXPfSSy9p9uzZSk5OdukOnjfqzz//1L333qvHH3/cstdE5jhNDwAAAAAAAJax9twEAAAAAAAAeDTCKAAAAAAAAFiGMAoAAAAAAACW4QLmOSA9PV1HjhxRcHCwbDZbXg8HAADcAGOMkpOTFRkZafndFj0J/RMAAO7FlR6KMCoHHDlyxNK7MQEAgNz3559/qkyZMnk9DLdF/wQAgHvKTg9FGJUDMm5F+eeffyokJCRH152amqply5apXbt28vHxydF15yeeUKcn1ChRp7vxhDo9oUaJOl2RlJSksmXLWnqraU9E/3TjqNO9eEKdnlCjRJ3uhjqzz5UeijAqB2QcWh4SEpIrzVRgYKBCQkLc/o3v7nV6Qo0SdbobT6jTE2qUqPN6cOpY7qJ/unHU6V48oU5PqFGiTndDna7LTg/FhRAAAAAAAABgGcIoAAAAAAAAWIYwCgAAAAAAAJYhjAIAAAAAAIBlCKMAAAAAAABgGcIoAAAAAAAAWIYwCgAAAAAAAJYhjAIAAAAAAIBlCKMAAAAAAABgGcIoAAAAAAAAWIYwCgAAAAAAAJYhjAIAAAAAAIBlCKMAAAAAAABgGcIoAAAAAAAAWIYwCgAAAAAAAJYhjAIAAAAAAIBlCKMAAAAAAABgGcIoAAAAAAAAWIYwCgAAAAAAAJYhjAIAAAAAAIBlCKMAAAAAAABgGcIoAAAAAAAAWIYwCgAAAAAAAJYhjAIAAAAAAIBlCKMAAAAAAABgGcIoAAAAAAAAWIYwCgAAAAAAAJYhjAIAAAAAAIBlCKMAAAAAAABgGcIoAAAAAAAAWIYwCgAAAAAAAJYhjAIAAAAAAIBlCKMAAAAAAABgGcIoAAAAAAAAWIYwCgAAAAAAAJYhjAIAAAAAAIBlCKMAAAAAAABgGcIoAAAAAAAAWIYwCgAAAAAAAJYhjAIAAAAAAIBlCKMAAAAAAABgGcIoAAAAAAAAWIYwCgAAAAAAAJYhjAIAAAAAAIBlCKMAAAAAAABgGcIoAAAAAAAAWIYwCgAAAAAAAJYhjAIAAAAAAIBlCKMAAAAAAABgGcIoAAAAAAAAWIYwCgAAAAAAAJYhjAIAAAAAAIBlCKMAAAAAAABgGcIoAAAAAAAAWIYwCgAAAAAAAJYhjAIAAAAAAIBlCKMAAAAAAABgGcIoAAAAAAAAWIYwCgAAAAAAAJYhjAIAAAAAAIBlCKMAAAAAAABgGcIoAAAAAAAAWKbAhFEJCQnq16+fihQpoiJFiqhfv346derUVZc5duyYBgwYoMjISAUGBqpDhw7as2eP03zr1q1T69atFRQUpKJFi6ply5b6999/c6kSAAAA69BDAQCA/KbAhFF9+vTRli1btHTpUi1dulRbtmxRv379spzfGKOuXbtq3759+uqrr7R582aVL19ebdu21ZkzZ+zzrVu3Th06dFC7du20YcMGbdy4UcOGDZOXV4HZNAAAAFmihwIAAPmNd14PIDt27dqlpUuXKi4uTo0aNZIkvfPOO2rSpIl2796tatWqOS2zZ88excXFafv27br55pslSbNmzVLJkiU1f/58PfDAA5Kkxx57TMOHD9eYMWPsy1atWtWCqgAAAHIXPRQAAMiPCkQYtW7dOhUpUsTeRElS48aNVaRIEa1duzbTRiolJUWS5O/vb59WqFAh+fr6as2aNXrggQd0/PhxrV+/Xn379lVUVJT27t2r6tWr6/nnn1ezZs2yHE9KSop9/ZKUlJQkSUpNTVVqauoN13u5jPXl9HrzG0+o0xNqlKjT3XhCnZ5Qo0Sd17MOd5Cfeij6p5xHne7FE+r0hBol6nQ31On6OrKjQIRR8fHxKlmypNP0kiVLKj4+PtNlqlevrvLly2vs2LF66623FBQUpOnTpys+Pl5Hjx6VJO3bt0+SFBMTo2nTpqlevXr64IMP1KZNG23fvj3Lb/cmTZqkCRMmOE1ftmyZAgMDr7fMq4qNjc2V9eY3nlCnJ9QoUae78YQ6PaFGiTqz4+zZszk4kryVn3oo+qfcQ53uxRPq9IQaJep0N9R5ba70UHkaRsXExGTalFxu48aNkiSbzeb0nDEm0+mS5OPjo4ULF2rQoEEqVqyYChUqpLZt26pjx472edLT0yVJQ4YM0f333y9Jql+/vn744Qe99957mjRpUqbrHjt2rEaOHGl/nJSUpLJly6pdu3YKCQm5aj2uSk1NVWxsrKKjo+Xj45Oj685PPKFOT6hRok534wl1ekKNEnW6IuOInfysIPZQ9E85jzrdiyfU6Qk1StTpbqgz+1zpofI0jBo2bJh69+591XkqVKig3377TceOHXN67u+//1Z4eHiWyzZo0EBbtmxRYmKizp8/rxIlSqhRo0Zq2LChJKlUqVKSpJo1azosV6NGDR06dCjL9fr5+cnPz89puo+PT669OXNz3fmJJ9TpCTVK1OluPKFOT6hRos7sLpvfFcQeiv4p91Cne/GEOj2hRok63Q11Zm/Z7MrTMCosLExhYWHXnK9JkyZKTEzUhg0bdOutt0qS1q9fr8TEREVFRV1z+SJFiki6eEHOTZs26bnnnpN0sUmLjIzU7t27Heb/v//7P4dv/wAAAPITeigAAFCQFYh779aoUUMdOnTQ4MGDFRcXp7i4OA0ePFidOnVyuPBm9erVtWjRIvvjzz77TCtXrrTfmjg6Olpdu3ZVu3btJF08bP3JJ5/Uq6++qs8//1x//PGHnnnmGf3+++8aNGiQ5XUCAADkJHooAACQHxWIC5hL0rx58zR8+HB7E3TnnXdq5syZDvPs3r1biYmJ9sdHjx7VyJEjdezYMZUqVUr33XefnnnmGYdlRowYoXPnzumxxx7TyZMnVbduXcXGxqpy5cq5XxQAAEAuo4cCAAD5TYEJo4oVK6aPPvroqvMYYxweDx8+XMOHD7/museMGaMxY8bc0PgAAADyI3ooAACQ3xSI0/QAAAAAAADgHgijAAAAAAAAYBnCKAAAAAAAAFiGMAoAAAAAAACWIYwCAAAAAACAZQijAAAAAAAAYBnCKAAAAAAAAFiGMAoAAAAAAACWIYwCAAAAAACAZQijAAAAAAAAYBnCKAAAAAAAAFiGMAoAAAAAAACWIYwCAAAAAACAZQijAAAAAAAAYBnCKAAAAAAAAFiGMAoAAAAAAACWIYwCAAAAAACAZQijAAAAAAAAYBnCKAAAAAAAAFiGMAoAAAAAAACWIYwCAAAAAACAZQijAAAAAAAAYBnCKAAAAAAAAFiGMAoAAAAAAACWIYwCAAAAAACAZQijAAAAAAAAYBnCKAAAAAAAAFiGMAoAAAAAAACWIYwCAAAAAACAZQijAAAAAAAAYBnCKAAAAAAAAFiGMAoAAAAAAACWIYwCAAAAAACAZQijAAAAAAAAYBnCKAAAAAAAAFiGMAoAAAAAAACWIYwCAAAAAACAZQijAAAAAAAAYBnCKAAAAAAAAFiGMAoAAAAAAACWIYwCAAAAAACAZQijAAAAAAAAYBnCKAAAAAAAAFiGMAoAAAAAAACWIYwCAAAAAACAZQijAAAAAAAAYBnCKAAAAAAAAFiGMAoAAAAAAACWIYwCAAAAAACAZQijAAAAAAAAYBnCKAAAAAAAAFiGMAoAAAAAAACWIYwCAAAAAACAZQijAAAAAAAAYBnCKAAAAAAAAFiGMAoAAAAAAACWIYwCAAAAAACAZQijAAAAAAAAYBnCKAAAAAAAAFiGMAoAAAAAAACWIYwCAAAAAACAZQijAAAAAAAAYBnCKAAAAAAAAFiGMAoAAAAAAACWIYwCAAAAAACAZQijAAAAAAAAYBnCKAAAAAAAAFiGMAoAAAAAAACWIYwCAAAAAACAZQijAAAAAAAAYBnCKAAAAAAAAFiGMAoAAAAAAACWIYwCAAAAAACAZQijAAAAAAAAYBnCKAAAAAAAAFiGMAoAAAAAAACWIYwCAAAAAACAZQijAAAAAAAAYBnCKAAAAAAAAFiGMAoAAAAAAACWIYwCAAAAAACAZQpMGJWQkKB+/fqpSJEiKlKkiPr166dTp05ddZljx45pwIABioyMVGBgoDp06KA9e/Y4zBMfH69+/fopIiJCQUFB+s9//qPPP/88FysBAACwDj0UAADIbwpMGNWnTx9t2bJFS5cu1dKlS7Vlyxb169cvy/mNMeratav27dunr776Sps3b1b58uXVtm1bnTlzxj5fv379tHv3bi1evFjbtm1Tt27d1KtXL23evNmKsgAAAHIVPRQAAMhvCkQYtWvXLi1dulTvvvuumjRpoiZNmuidd97RkiVLtHv37kyX2bNnj+Li4vTGG2/olltuUbVq1TRr1iydPn1a8+fPt8+3bt06PfLII7r11ltVqVIljRs3TkWLFtWvv/5qVXkAAAC5gh4KAADkR955PYDsWLdunYoUKaJGjRrZpzVu3FhFihTR2rVrVa1aNadlUlJSJEn+/v72aYUKFZKvr6/WrFmjBx54QJLUrFkzLViwQHfccYeKFi2qTz/9VCkpKWrZsmWW40lJSbGvX5KSkpIkSampqUpNTb2hWq+Usb6cXm9+4wl1ekKNEnW6G0+o0xNqlKjzetbhDvJTD0X/lPOo0714Qp2eUKNEne6GOl1fR3YUiDAqPj5eJUuWdJpesmRJxcfHZ7pM9erVVb58eY0dO1ZvvfWWgoKCNH36dMXHx+vo0aP2+RYsWKBevXqpePHi8vb2VmBgoBYtWqTKlStnOZ5JkyZpwoQJTtOXLVumwMDA66jw2mJjY3NlvfmNJ9TpCTVK1OluPKFOT6hRos7sOHv2bA6OJG/lpx6K/in3UKd78YQ6PaFGiTrdDXVemys9VJ6GUTExMZk2JZfbuHGjJMlmszk9Z4zJdLok+fj4aOHChRo0aJCKFSumQoUKqW3bturYsaPDfOPGjVNCQoKWL1+usLAwffnll+rRo4dWr16t2rVrZ7rusWPHauTIkfbHSUlJKlu2rNq1a6eQkJCr1uOq1NRUxcbGKjo6Wj4+Pjm67vzEE+r0hBol6nQ3nlCnJ9QoUacrMo7Yyc8KYg9F/5TzqNO9eEKdnlCjRJ3uhjqzz5UeKk/DqGHDhql3795XnadChQr67bffdOzYMafn/v77b4WHh2e5bIMGDbRlyxYlJibq/PnzKlGihBo1aqSGDRtKkvbu3auZM2dq+/btuvnmmyVJdevW1erVq/X666/rzTffzHS9fn5+8vPzc5ru4+OTa2/O3Fx3fuIJdXpCjRJ1uhtPqNMTapSoM7vL5ncFsYeif8o91OlePKFOT6hRok53Q53ZWza78jSMCgsLU1hY2DXna9KkiRITE7VhwwbdeuutkqT169crMTFRUVFR11y+SJEiki5ekHPTpk167rnnJF06hMzLy/E67oUKFVJ6erpLtQAAAFiFHgoAABRkBeJuejVq1FCHDh00ePBgxcXFKS4uToMHD1anTp0cLrxZvXp1LVq0yP74s88+08qVK+23Jo6OjlbXrl3Vrl07+/xVqlTRkCFDtGHDBu3du1cvvfSSYmNj1bVrV6vLBAAAyFH0UAAAID8qEGGUJM2bN0+1a9dWu3bt1K5dO9WpU0cffvihwzy7d+9WYmKi/fHRo0fVr18/Va9eXcOHD1e/fv0cbkns4+Ojb7/9ViVKlFDnzp1Vp04dffDBB5o7d65uv/12y2oDAADILfRQAAAgvykQd9OTpGLFiumjjz666jzGGIfHw4cP1/Dhw6+6TNWqVbVw4cIbHh8AAEB+RA8FAADymwJzZBQAAAAAAAAKPsIoAAAAAAAAWIYwCgAAAAAAAJYhjAIAAAAAAIBlCKMAAAAAAABgGcIoAAAAAAAAWIYwCgAAAAAAAJYhjAIAAAAAAIBlCKMAAAAAAABgGcIoAAAAAAAAWIYwCgAAAAAAAJYhjAIAAAAAAIBlCKMAAAAAAABgGcIoAAAAAAAAWIYwCgAAAAAAAJYhjAIAAAAAAIBlCKMAAAAAAABgGcIoAAAAAAAAWIYwCgAAAAAAAJYhjAIAAAAAAIBlCKMAAAAAAABgGcIoAAAAAAAAWIYwCgAAAAAAAJYhjAIAAAAAAIBlCKMAAAAAAABgGcIoAAAAAAAAWIYwCgAAAAAAAJYhjAIAAAAAAIBlCKMAAAAAAABgGcIoAAAAAAAAWMY7OzP99ttv2V5hnTp1rnswAAAA7oL+CQAAIHPZCqPq1asnm80mY4xsNttV501LS8uRgQEAABRk9E8AAACZy9Zpevv379e+ffu0f/9+LVy4UBUrVtSsWbO0efNmbd68WbNmzVLlypW1cOHC3B4vAABAgUD/BAAAkLlsHRlVvnx5+7979OihV199Vbfffrt9Wp06dVS2bFk988wz6tq1a44PEgAAoKChfwIAAMicyxcw37ZtmypWrOg0vWLFitq5c2eODAoAAMCd0D8BAABc4nIYVaNGDU2cOFHnzp2zT0tJSdHEiRNVo0aNHB0cAACAO6B/AgAAuCRbp+ld7s0331Tnzp1VtmxZ1a1bV5K0detW2Ww2LVmyJMcHCAAAUNDRPwEAAFzichh16623av/+/froo4/0+++/yxijXr16qU+fPgoKCsqNMQIAABRo9E8AAACXuBRGpaamqlq1alqyZIkefPDB3BoTAACA26B/AgAAcOTSNaN8fHyUkpIim82WW+MBAABwK/RPAAAAjly+gPkjjzyiKVOm6MKFC7kxHgAAALdD/wQAAHCJy9eMWr9+vX744QctW7ZMtWvXdrrOwRdffJFjgwMAAHAH9E8AAACXuBxGFS1aVHfffXdujAUAAMAt0T8BAABc4nIY9f777+fGOAAAANwW/RMAAMAlLl8zCgAAAAAAALheLh8ZJUmff/65Pv30Ux06dEjnz593eO7XX3/NkYEBAAC4E/onAACAi1w+MurVV1/V/fffr5IlS2rz5s269dZbVbx4ce3bt08dO3bMjTECAAAUaPRPAAAAl7gcRs2aNUtvv/22Zs6cKV9fX40aNUqxsbEaPny4EhMTc2OMAAAABRr9EwAAwCUuh1GHDh1SVFSUJCkgIEDJycmSpH79+mn+/Pk5OzoAAAA3QP8EAABwicthVEREhE6cOCFJKl++vOLi4iRJ+/fvlzEmZ0cHAADgBuifAAAALnE5jGrdurW+/vprSdKgQYP02GOPKTo6Wr169dJdd92V4wMEAAAo6OifAAAALnH5bnpvv/220tPTJUkPPfSQihUrpjVr1qhz58566KGHcnyAAAAABR39EwAAwCUuh1FeXl7y8rp0QFXPnj3Vs2fPHB0UAACAO6F/AgAAuMTlMKpp06Zq0aKFWrZsqaZNmyooKCg3xgUAAOA26J8AAAAucfmaUZ06ddKvv/6q7t27KzQ0VE2aNNGYMWO0dOlSnT59OjfGCAAAUKDRPwEAAFzichg1duxYLV26VAkJCfrpp5/UpUsXbdmyRXfeeaeKFy+eG2MEAAAo0OifAAAALnH5NL0Me/bs0datW7V161b99ttvCgkJ0W233ZaTYwMAAHAr9E8AAADXEUb16tVLP/30k9LT09W8eXM1b95cY8eOVZ06dXJjfAAAAAUe/RMAAMAlLodRn332mcLCwjRgwAC1atVKt912mwoXLpwbYwMAAHAL9E8AAACXuHzNqJMnT+rdd9/VhQsXNG7cOIWFhalRo0YaPXq0vvvuu9wYIwAAQIFG/wQAAHCJy2FU0aJFdeedd2r69On65ZdftGPHDtWsWVPTp09Xp06dcmOMAAAABRr9EwAAwCUun6Z38uRJrVq1SitXrtTKlSu1Y8cOFStWTF26dFGrVq1yY4wAAAAFGv0TAADAJS6HUSVKlFBYWJhuu+02DR48WC1btlStWrVyY2wAAABugf4JAADgEpfDqK1bt9I8AQAAuID+CQAA4BKXrxlVq1YtXbhwQcuXL9dbb72l5ORkSdKRI0d0+vTpHB8gAABAQUf/BAAAcInLR0YdPHhQHTp00KFDh5SSkqLo6GgFBwdr6tSpOnfunN58883cGCcAAECBRf8EAABwictHRj366KNq2LChEhISFBAQYJ9+11136YcffsjRwQEAALgD+icAAIBLXD4yas2aNfr555/l6+vrML18+fL666+/cmxgAAAA7oL+CQAA4BKXj4xKT09XWlqa0/TDhw8rODg4RwYFAADgTuifAAAALnE5jIqOjtaMGTPsj202m06fPq3x48fr9ttvz8mxAQAAuAX6JwAAgEtcPk3v5ZdfVqtWrVSzZk2dO3dOffr00Z49exQWFqb58+fnxhgBAAAKNPonAACAS1wOoyIjI7VlyxbNnz9fv/76q9LT0zVo0CD17dvX4YKcAAAAuIj+CQAA4BKXwyhJCggI0MCBAzVw4ED7tKNHj+rJJ5/UzJkzc2xwAAAA7oL+CQAA4CKXwqidO3dqxYoV8vHxUc+ePVW0aFH9888/ev755/Xmm2+qYsWKuTVOAACAAon+CQAAwFG2L2C+ZMkS1a9fX4888ogeeughNWzYUCtWrFCNGjW0ZcsWffbZZ9q5c2dujhUAAKBAoX8CAABwlu0w6vnnn9dDDz2kpKQkTZs2Tfv27dNDDz2khQsXasWKFerUqVNujhMAAKDAoX8CAABwlu0wateuXfrvf/+rwoULa/jw4fLy8tKMGTPUvHnz3BwfAABAgUX/BAAA4CzbYVRSUpKKFi0qSfL29lZAQIBuuumm3BoXAABAgUf/BAAA4MzlC5jHx8dLkowx2r17t86cOeMwT506dXJudAAAAAUc/RMAAIAjl8KoNm3ayBhjf5xxnQObzSZjjGw2m9LS0nJ2hAAAAAUY/RMAAICjbIdR+/fvz81xAAAAuB36JwAAAGfZvmZU+fLls/WTW55//nlFRUUpMDDQfu2FazHGKCYmRpGRkQoICFDLli21Y8cOh3lSUlL0yCOPKCwsTEFBQbrzzjt1+PDhXKgAAAB4mrzunyR6KAAAkP9kO4zKa+fPn1ePHj00dOjQbC8zdepUTZ8+XTNnztTGjRsVERGh6OhoJScn2+cZMWKEFi1apE8++URr1qzR6dOn1alTJw6XBwAAboEeCgAA5DcuXTMqL02YMEGSNGfOnGzNb4zRjBkz9PTTT6tbt26SpLlz5yo8PFwff/yxhgwZosTERM2ePVsffvih2rZtK0n66KOPVLZsWS1fvlzt27fPlVoAAACsQg8FAADymwITRrlq//79io+PV7t27ezT/Pz81KJFC61du1ZDhgzRL7/8otTUVId5IiMjVatWLa1duzbPG6k9x5L1xa9/au8hL/2+fI8KeRXK0/HkprT0NLev0xNqlKjT3XhCnZ5Qo+S+dXapF6mq4cF5PQy34g491IdxhxTnhu/3K7nr7/WVqNN9eEKNEnW6G3ess0Swn/pHVcjTMbhtGJVxC+Xw8HCH6eHh4Tp48KB9Hl9fX4WGhjrNk7F8ZlJSUpSSkmJ/nJSUJElKTU1VampqjoxfkvbEJ+mNVfsleUl/ecIFUD2hTk+oUaJOd+MJdXpCjZI71lkjIkgVivnbH2d8Dt/I53FOfpYXRLnVQ1nVP0nSgk2HtfuY+73fM0ed7sUT6vSEGiXqdDfuVWf18MLqc0tph2lW91DXFUZduHBBK1eu1N69e9WnTx8FBwfryJEjCgkJUeHChbO9npiYGPuh41nZuHGjGjZseD3DlHTxtsmXy7iF8tVca55JkyZlOu5ly5YpMDDw+gaaib/OSM0jCsxlvQAAsNzBHb/o2wPO02NjY697nWfPnr3+AV1FTvVPUsHsoazqnyTpJj+bwiOuPlYAADxViG+ivv3220yfs6qHcjmMOnjwoDp06KBDhw4pJSVF0dHRCg4O1tSpU3Xu3Dm9+eab2V7XsGHD1Lt376vOU6FCBVeHKEmKiIiQdPGbu1KlStmnHz9+3P5NX0REhM6fP6+EhASHb/aOHz+uqKioLNc9duxYjRw50v44KSlJZcuWVbt27RQSEnJd483KgNRUxcbGKjo6Wj4+Pjm67vwk1QPq9IQaJep0N55QpyfUKFGnKzKO2MlJOdk/SQWzh7Kyf4rm/e5WqNN9eEKNEnW6G+rMPld6KJfDqEcffVQNGzbU1q1bVbx4cfv0u+66Sw888IBL6woLC1NYWJirQ8iWihUrKiIiQrGxsapfv76ki3eTWbVqlaZMmSJJatCggXx8fBQbG6uePXtKko4ePart27dr6tSpWa7bz89Pfn5+TtN9fHxy7c2Zm+vOTzyhTk+oUaJOd+MJdXpCjRJ1ZnfZnJaT/ZNUMHso+qfcQ53uxRPq9IQaJep0N9SZvWWzy+Uwas2aNfr555/l6+vrML18+fL666+/XF1dth06dEgnT57UoUOHlJaWpi1btkiSqlSpYj+0vXr16po0aZLuuusu2Ww2jRgxQi+88IKqVq2qqlWr6oUXXlBgYKD69OkjSSpSpIgGDRqkxx9/XMWLF1exYsX0xBNPqHbt2vY7wwAAANyovOqfJHooAACQ/7gcRqWnpystLc1p+uHDhxUcnHt3s3n22Wc1d+5c++OMb+pWrFihli1bSpJ2796txMRE+zyjRo3Sv//+q4cfflgJCQlq1KiRli1b5jDOl19+Wd7e3urZs6f+/fdftWnTRnPmzFGhQu5xlXwAAJD38qp/kuihAABA/uNyGBUdHa0ZM2bo7bfflnTx4panT5/W+PHjdfvtt+f4ADPMmTNHc+bMueo8xhiHxzabTTExMYqJiclyGX9/f7322mt67bXXcmCUAAAAzvKqf5LooQAAQP7jchj18ssvq1WrVqpZs6bOnTunPn36aM+ePQoLC9P8+fNzY4wAAAAFGv0TAADAJS6HUZGRkdqyZYvmz5+vX3/9Venp6Ro0aJD69u2rgICA3BgjAABAgUb/BAAAcInLYZQkBQQEaODAgRo4cGBOjwcAAMAt0T8BAABc5HIYtXjx4kyn22w2+fv7q0qVKqpYseINDwwAAMBd0D8BAABc4nIY1bVrV9lstkwvdGmMkc1mU7NmzfTll18qNDQ0xwYKAABQUNE/AQAAXOLl6gKxsbG65ZZbFBsbq8TERCUmJio2Nla33nqrlixZop9++kknTpzQE088kRvjBQAAKHDonwAAAC5x+cioRx99VG+//baioqLs09q0aSN/f389+OCD2rFjh2bMmMH1EAAAAP4/+icAAIBLXD4yau/evQoJCXGaHhISon379kmSqlatqn/++efGRwcAAOAG6J8AAAAucTmMatCggZ588kn9/fff9ml///23Ro0apVtuuUWStGfPHpUpUybnRgkAAFCA0T8BAABc4vJperNnz1aXLl1UpkwZlS1bVjabTYcOHVKlSpX01VdfSZJOnz6tZ555JscHCwAAUBDRPwEAAFzichhVrVo17dq1S99//73+7//+T8YYVa9eXdHR0fLyunigVdeuXXN6nAAAAAUW/RMAAMAlLodR0sXbEHfo0EEdOnTI6fEAAAC4JfonAACAi64rjDpz5oxWrVqlQ4cO6fz58w7PDR8+PEcGBgAA4E7onwAAAC5yOYzavHmzbr/9dp09e1ZnzpxRsWLF9M8//ygwMFAlS5akmQIAALgC/RMAAMAlLt9N77HHHlPnzp118uRJBQQEKC4uTgcPHlSDBg00bdq03BgjAABAgUb/BAAAcInLYdSWLVv0+OOPq1ChQipUqJBSUlJUtmxZTZ06VU899VRujBEAAKBAo38CAAC4xOUwysfHRzabTZIUHh6uQ4cOSZKKFCli/zcAAAAuoX8CAAC4xOVrRtWvX1+bNm3STTfdpFatWunZZ5/VP//8ow8//FC1a9fOjTECAAAUaPRPAAAAl7h8ZNQLL7ygUqVKSZKee+45FS9eXEOHDtXx48f19ttv5/gAAQAACjr6JwAAgEtcOjLKGKMSJUro5ptvliSVKFFC3377ba4MDAAAwB3QPwEAADhy6cgoY4yqVq2qw4cP59Z4AAAA3Ar9EwAAgCOXwigvLy9VrVpVJ06cyK3xAAAAuBX6JwAAAEcuXzNq6tSpevLJJ7V9+/bcGA8AAIDboX8CAAC4xOW76d177706e/as6tatK19fXwUEBDg8f/LkyRwbHAAAgDugfwIAALjE5TBqxowZuTAMAAAA90X/BAAAcInLYVT//v1zYxwAAABui/4JAADgEpevGSVJe/fu1bhx43TPPffo+PHjkqSlS5dqx44dOTo4AAAAd0H/BAAAcJHLYdSqVatUu3ZtrV+/Xl988YVOnz4tSfrtt980fvz4HB8gAABAQUf/BAAAcInLYdSYMWM0ceJExcbGytfX1z69VatWWrduXY4ODgAAwB3QPwEAAFzichi1bds23XXXXU7TS5QooRMnTuTIoAAAANwJ/RMAAMAlLodRRYsW1dGjR52mb968WaVLl86RQQEAALgT+icAAIBLXA6j+vTpo9GjRys+Pl42m03p6en6+eef9cQTT+i+++7LjTECAAAUaPRPAAAAl7gcRj3//PMqV66cSpcurdOnT6tmzZpq3ry5oqKiNG7cuNwYIwAAQIFG/wQAAHCJt6sL+Pj4aN68efrf//6nzZs3Kz09XfXr11fVqlVzY3wAAAAFHv0TAADAJS6HUatWrVKLFi1UuXJlVa5cOTfGBAAA4FbonwAAAC5x+TS96OholStXTmPGjNH27dtzY0wAAABuhf4JAADgEpfDqCNHjmjUqFFavXq16tSpozp16mjq1Kk6fPhwbowPAACgwKN/AgAAuMTlMCosLEzDhg3Tzz//rL1796pXr1764IMPVKFCBbVu3To3xggAAFCg0T8BAABc4nIYdbmKFStqzJgxmjx5smrXrq1Vq1bl1LgAAADcEv0TAADwdNcdRv388896+OGHVapUKfXp00c333yzlixZkpNjAwAAcCv0TwAAANdxN72nnnpK8+fP15EjR9S2bVvNmDFDXbt2VWBgYG6MDwAAoMCjfwIAALjE5TBq5cqVeuKJJ9SrVy+FhYU5PLdlyxbVq1cvp8YGAADgFuifAAAALnE5jFq7dq3D48TERM2bN0/vvvuutm7dqrS0tBwbHAAAgDugfwIAALjkuq8Z9eOPP+ree+9VqVKl9Nprr+n222/Xpk2bcnJsAAAAboX+CQAAwMUjow4fPqw5c+bovffe05kzZ9SzZ0+lpqZq4cKFqlmzZm6NEQAAoMCifwIAAHCU7SOjbr/9dtWsWVM7d+7Ua6+9piNHjui1117LzbEBAAAUaPRPAAAAzrJ9ZNSyZcs0fPhwDR06VFWrVs3NMQEAALgF+icAAABn2T4yavXq1UpOTlbDhg3VqFEjzZw5U3///Xdujg0AAKBAo38CAABwlu0wqkmTJnrnnXd09OhRDRkyRJ988olKly6t9PR0xcbGKjk5OTfHCQAAUODQPwEAADhz+W56gYGBGjhwoNasWaNt27bp8ccf1+TJk1WyZEndeeeduTFGAACAAo3+CQAA4BKXw6jLVatWTVOnTtXhw4c1f/78nBoTAACA26J/AgAAnu6GwqgMhQoVUteuXbV48eKcWB0AAIDbo38CAACeKkfCKAAAAAAAACA7CKMAAAAAAABgGcIoAAAAAAAAWIYwCgAAAAAAAJYhjAIAAAAAAIBlCKMAAAAAAABgGcIoAAAAAAAAWIYwCgAAAAAAAJYhjAIAAAAAAIBlCKMAAAAAAABgGcIoAAAAAAAAWIYwCgAAAAAAAJYhjAIAAAAAAIBlCKMAAAAAAABgGcIoAAAAAAAAWIYwCgAAAAAAAJYhjAIAAAAAAIBlCKMAAAAAAABgGcIoAAAAAAAAWIYwCgAAAAAAAJYhjAIAAAAAAIBlCKMAAAAAAABgGcIoAAAAAAAAWIYwCgAAAAAAAJYhjAIAAAAAAIBlCKMAAAAAAABgGcIoAAAAAAAAWIYwCgAAAAAAAJYhjAIAAAAAAIBlCkwY9fzzzysqKkqBgYEqWrRotpYxxigmJkaRkZEKCAhQy5YttWPHDvvzJ0+e1COPPKJq1aopMDBQ5cqV0/Dhw5WYmJhLVQAAAFiLHgoAAOQ3BSaMOn/+vHr06KGhQ4dme5mpU6dq+vTpmjlzpjZu3KiIiAhFR0crOTlZknTkyBEdOXJE06ZN07Zt2zRnzhwtXbpUgwYNyq0yAAAALEUPBQAA8hvvvB5Adk2YMEGSNGfOnGzNb4zRjBkz9PTTT6tbt26SpLlz5yo8PFwff/yxhgwZolq1amnhwoX2ZSpXrqznn39e9957ry5cuCBv7wKzeQAAADJFDwUAAPKbAnNklKv279+v+Ph4tWvXzj7Nz89PLVq00Nq1a7NcLjExUSEhITRRAADAI9FDAQCA3Oa23UJ8fLwkKTw83GF6eHi4Dh48mOkyJ06c0HPPPachQ4Zcdd0pKSlKSUmxP05KSpIkpaamKjU19UaG7SRjfTm93vzGE+r0hBol6nQ3nlCnJ9QoUef1rMNT5VYPRf+U86jTvXhCnZ5Qo0Sd7oY6XV9HduRpGBUTE2M/dDwrGzduVMOGDa/7NWw2m8NjY4zTNOliQ3THHXeoZs2aGj9+/FXXOWnSpEzHvWzZMgUGBl73WK8mNjY2V9ab33hCnZ5Qo0Sd7sYT6vSEGiXqzI6zZ8/m4EhyR0Hsoeifcg91uhdPqNMTapSo091Q57W50kPlaRg1bNgw9e7d+6rzVKhQ4brWHRERIenit3ulSpWyTz9+/LjTN33Jycnq0KGDChcurEWLFsnHx+eq6x47dqxGjhxpf5yUlKSyZcuqXbt2CgkJua7xZiU1NVWxsbGKjo6+5rgKMk+o0xNqlKjT3XhCnZ5Qo0Sdrsg4Yic/K4g9FP1TzqNO9+IJdXpCjRJ1uhvqzD5Xeqg8DaPCwsIUFhaWK+uuWLGiIiIiFBsbq/r160u6eDeZVatWacqUKfb5kpKS1L59e/n5+Wnx4sXy9/e/5rr9/Pzk5+fnNN3HxyfX3py5ue78xBPq9IQaJep0N55QpyfUKFFndpfN7wpiD0X/lHuo0714Qp2eUKNEne6GOrO3bHYVmAuYHzp0SFu2bNGhQ4eUlpamLVu2aMuWLTp9+rR9nurVq2vRokWSLh5aPmLECL3wwgtatGiRtm/frgEDBigwMFB9+vSRdPHbvHbt2unMmTOaPXu2kpKSFB8fr/j4eKWlpeVJnQAAADmJHgoAAOQ3BeYC5s8++6zmzp1rf5zxTd2KFSvUsmVLSdLu3buVmJhon2fUqFH6999/9fDDDyshIUGNGjXSsmXLFBwcLEn65ZdftH79eklSlSpVHF5v//791314OwAAQH5BDwUAAPKbAhNGzZkzR3PmzLnqPMYYh8c2m00xMTGKiYnJdP6WLVs6LQMAAOBO6KEAAEB+U2BO0wMAAAAAAEDBRxgFAAAAAAAAyxBGAQAAAAAAwDKEUQAAAAAAALAMYRQAAAAAAAAsQxgFAAAAAAAAyxBGAQAAAAAAwDKEUQAAAAAAALAMYRQAAAAAAAAsQxgFAAAAAAAAyxBGAQAAAAAAwDKEUQAAAAAAALAMYRQAAAAAAAAsQxgFAAAAAAAAyxBGAQAAAAAAwDKEUQAAAAAAALAMYRQAAAAAAAAsQxgFAAAAAAAAyxBGAQAAAAAAwDKEUQAAAAAAALAMYRQAAAAAAAAsQxgFAAAAAAAAyxBGAQAAAAAAwDKEUQAAAAAAALAMYRQAAAAAAAAsQxgFAAAAAAAAyxBGAQAAAAAAwDKEUQAAAAAAALAMYRQAAAAAAAAsQxgFAAAAAAAAyxBGAQAAAAAAwDKEUQAAAAAAALAMYRQAAAAAAAAsQxgFAAAAAAAAyxBGAQAAAAAAwDKEUQAAAAAAALAMYRQAAAAAAAAsQxgFAAAAAAAAyxBGAQAAAAAAwDKEUQAAAAAAALAMYRQAAAAAAAAsQxgFAAAAAAAAyxBGAQAAAAAAwDKEUQAAAAAAALAMYRQAAAAAAAAsQxgFAAAAAAAAyxBGAQAAAAAAwDKEUQAAAAAAALAMYRQAAAAAAAAsQxgFAAAAAAAAyxBGAQAAAAAAwDKEUQAAAAAAALAMYRQAAAAAAAAsQxgFAAAAAAAAyxBGAQAAAAAAwDKEUQAAAAAAALAMYRQAAAAAAAAsQxgFAAAAAAAAyxBGAQAAAAAAwDKEUQAAAAAAALAMYRQAAAAAAAAsQxgFAAAAAAAAyxBGAQAAAAAAwDKEUQAAAAAAALAMYRQAAAAAAAAsQxgFAAAAAAAAyxBGAQAAAAAAwDKEUQAAAAAAALAMYRQAAAAAAAAsQxgFAAAAAAAAyxBGAQAAAAAAwDKEUQAAAAAAALAMYRQAAAAAAAAsQxgFAAAAAAAAyxBGAQAAAAAAwDKEUQAAAAAAALAMYRQAAAAAAAAsQxgFAAAAAAAAyxBGAQAAAAAAwDKEUQAAAAAAALAMYRQAAAAAAAAsU2DCqOeff15RUVEKDAxU0aJFs7WMMUYxMTGKjIxUQECAWrZsqR07dmQ5b8eOHWWz2fTll1/m3MABAADyED0UAADIbwpMGHX+/Hn16NFDQ4cOzfYyU6dO1fTp0zVz5kxt3LhRERERio6OVnJystO8M2bMkM1my8khAwAA5Dl6KAAAkN945/UAsmvChAmSpDlz5mRrfmOMZsyYoaefflrdunWTJM2dO1fh4eH6+OOPNWTIEPu8W7du1fTp07Vx40aVKlUqx8cOAACQV+ihAABAflNgjoxy1f79+xUfH6927drZp/n5+alFixZau3atfdrZs2d1zz33aObMmYqIiMiLoQIAAOQb9FAAACC3FZgjo1wVHx8vSQoPD3eYHh4eroMHD9ofP/bYY4qKilKXLl2yve6UlBSlpKTYHyclJUmSUlNTlZqaeiPDdpKxvpxeb37jCXV6Qo0SdbobT6jTE2qUqPN61uGpcquHon/KedTpXjyhTk+oUaJOd0Odrq8jO/I0jIqJibEfOp6VjRs3qmHDhtf9Gldew8AYY5+2ePFi/fjjj9q8ebNL65w0aVKm4162bJkCAwOve6xXExsbmyvrzW88oU5PqFGiTnfjCXV6Qo0SdWbH2bNnc3AkuaMg9lD0T7mHOt2LJ9TpCTVK1OluqPPaXOmh8jSMGjZsmHr37n3VeSpUqHBd6844XDw+Pt7hGgbHjx+3f9P3448/au/evU53lrn77rt12223aeXKlZmue+zYsRo5cqT9cVJSksqWLat27dopJCTkusabldTUVMXGxio6Olo+Pj45uu78xBPq9IQaJep0N55QpyfUKFGnKzKO2MnPCmIPRf+U86jTvXhCnZ5Qo0Sd7oY6s8+VHipPw6iwsDCFhYXlyrorVqyoiIgIxcbGqn79+pIu3k1m1apVmjJliiRpzJgxeuCBBxyWq127tl5++WV17tw5y3X7+fnJz8/PabqPj0+uvTlzc935iSfU6Qk1StTpbjyhTk+oUaLO7C6b3xXEHor+KfdQp3vxhDo9oUaJOt0NdWZv2ewqMNeMOnTokE6ePKlDhw4pLS1NW7ZskSRVqVJFhQsXliRVr15dkyZN0l133SWbzaYRI0bohRdeUNWqVVW1alW98MILCgwMVJ8+fSRd/OYvswtulitXThUrVrSsNgAAgNxCDwUAAPKbAhNGPfvss5o7d679ccY3dStWrFDLli0lSbt371ZiYqJ9nlGjRunff//Vww8/rISEBDVq1EjLli1TcHCwpWMHAADIK/RQAAAgvykwYdScOXM0Z86cq85jjHF4bLPZFBMTo5iYmGy/zpXrAAAAKMjooQAAQH7jldcDAAAAAAAAgOcgjAIAAAAAAIBlCKMAAAAAAABgGcIoAAAAAAAAWIYwCgAAAAAAAJYhjAIAAAAAAIBlCKMAAAAAAABgGcIoAAAAAAAAWIYwCgAAAAAAAJYhjAIAAAAAAIBlCKMAAAAAAABgGcIoAAAAAAAAWIYwCgAAAAAAAJYhjAIAAAAAAIBlCKMAAAAAAABgGcIoAAAAAAAAWIYwCgAAAAAAAJYhjAIAAAAAAIBlCKMAAAAAAABgGcIoAAAAAAAAWIYwCgAAAAAAAJYhjAIAAAAAAIBlCKMAAAAAAABgGcIoAAAAAAAAWIYwCgAAAAAAAJYhjAIAAAAAAIBlCKMAAAAAAABgGcIoAAAAAAAAWIYwCgAAAAAAAJYhjAIAAAAAAIBlCKMAAAAAAABgGcIoAAAAAAAAWIYwCgAAAAAAAJYhjAIAAAAAAIBlCKMAAAAAAABgGcIoAAAAAAAAWIYwCgAAAAAAAJYhjAIAAAAAAIBlCKMAAAAAAABgGcIoAAAAAAAAWIYwCgAAAAAAAJYhjAIAAAAAAIBlCKMAAAAAAABgGcIoAAAAAAAAWIYwCgAAAAAAAJYhjAIAAAAAAIBlCKMAAAAAAABgGcIoAAAAAAAAWIYwCgAAAAAAAJYhjAIAAAAAAIBlCKMAAAAAAABgGcIoAAAAAAAAWIYwCgAAAAAAAJYhjAIAAAAAAIBlCKMAAAAAAABgGcIoAAAAAAAAWIYwCgAAAAAAAJYhjAIAAAAAAIBlCKMAAAAAAABgGcIoAAAAAAAAWIYwCgAAAAAAAJYhjAIAAAAAAIBlvPN6AO7AGCNJSkpKyvF1p6am6uzZs0pKSpKPj0+Orz+/8IQ6PaFGiTrdjSfU6Qk1StTpiozP84zPd+QO+qcbR53uxRPq9IQaJep0N9SZfa70UIRROSA5OVmSVLZs2TweCQAAyCnJyckqUqRIXg/DbdE/AQDgnrLTQ9kMX/vdsPT0dB05ckTBwcGy2Ww5uu6kpCSVLVtWf/75p0JCQnJ03fmJJ9TpCTVK1OluPKFOT6hRok5XGGOUnJysyMhIeXlxRYPcQv9046jTvXhCnZ5Qo0Sd7oY6s8+VHoojo3KAl5eXypQpk6uvERIS4tZv/AyeUKcn1ChRp7vxhDo9oUaJOrOLI6JyH/1TzqFO9+IJdXpCjRJ1uhvqzJ7s9lB83QcAAAAAAADLEEYBAAAAAADAMoRR+Zyfn5/Gjx8vPz+/vB5KrvKEOj2hRok63Y0n1OkJNUrUCc/iKe8D6nQvnlCnJ9QoUae7oc7cwQXMAQAAAAAAYBmOjAIAAAAAAIBlCKMAAAAAAABgGcIoAAAAAAAAWIYwKh+bNWuWKlasKH9/fzVo0ECrV6/O6yFlW0xMjGw2m8NPRESE/XljjGJiYhQZGamAgAC1bNlSO3bscFhHSkqKHnnkEYWFhSkoKEh33nmnDh8+bHUpDn766Sd17txZkZGRstls+vLLLx2ez6m6EhIS1K9fPxUpUkRFihRRv379dOrUqVyu7pJr1TlgwACn/du4cWOHefJ7nZMmTdItt9yi4OBglSxZUl27dtXu3bsd5nGH/ZmdOt1hf77xxhuqU6eOQkJCFBISoiZNmui7776zP+8O+1K6dp3usC+vNGnSJNlsNo0YMcI+zV32J3IPPRQ9VF78XntC/yR5Rg9F/3RRQd+PGeifLsp3+9MgX/rkk0+Mj4+Peeedd8zOnTvNo48+aoKCgszBgwfzemjZMn78eHPzzTebo0eP2n+OHz9uf37y5MkmODjYLFy40Gzbts306tXLlCpVyiQlJdnneeihh0zp0qVNbGys+fXXX02rVq1M3bp1zYULF/KiJGOMMd9++615+umnzcKFC40ks2jRIofnc6quDh06mFq1apm1a9eatWvXmlq1aplOnTpZVeY16+zfv7/p0KGDw/49ceKEwzz5vc727dub999/32zfvt1s2bLF3HHHHaZcuXLm9OnT9nncYX9mp0532J+LFy8233zzjdm9e7fZvXu3eeqpp4yPj4/Zvn27McY99mV26nSHfXm5DRs2mAoVKpg6deqYRx991D7dXfYncgc9FD1UXv1ee0L/ZIxn9FD0T/RPBW1fXq6g9E+EUfnUrbfeah566CGHadWrVzdjxozJoxG5Zvz48aZu3bqZPpeenm4iIiLM5MmT7dPOnTtnihQpYt58801jjDGnTp0yPj4+5pNPPrHP89dffxkvLy+zdOnSXB17dl3ZZORUXTt37jSSTFxcnH2edevWGUnm999/z+WqnGXVTHXp0iXLZQpincePHzeSzKpVq4wx7rs/r6zTGPfcn8YYExoaat5991233ZcZMuo0xr32ZXJysqlataqJjY01LVq0sDdT7r4/cePooeih8sPvtaf0T8Z4Rg9F/3RRQd+Pl6N/yvv9yWl6+dD58+f1yy+/qF27dg7T27Vrp7Vr1+bRqFy3Z88eRUZGqmLFiurdu7f27dsnSdq/f7/i4+Md6vPz81OLFi3s9f3yyy9KTU11mCcyMlK1atXKt9sgp+pat26dihQpokaNGtnnady4sYoUKZKval+5cqVKliypm266SYMHD9bx48ftzxXEOhMTEyVJxYoVk+S++/PKOjO40/5MS0vTJ598ojNnzqhJkyZuuy+vrDODu+zL//73v7rjjjvUtm1bh+nuuj+RM+ih6KHy+++1u/wffTlP6KHony4q6PtRon/KT/vT2+XqkOv++ecfpaWlKTw83GF6eHi44uPj82hUrmnUqJE++OAD3XTTTTp27JgmTpyoqKgo7dixw15DZvUdPHhQkhQfHy9fX1+FhoY6zZNft0FO1RUfH6+SJUs6rb9kyZL5pvaOHTuqR48eKl++vPbv369nnnlGrVu31i+//CI/P78CV6cxRiNHjlSzZs1Uq1Yt+/gk99qfmdUpuc/+3LZtm5o0aaJz586pcOHCWrRokWrWrGn/YHSXfZlVnZL77MtPPvlEv/76qzZu3Oj0nDv+biLn0EPRQ+Xn32t3+T/6cp7QQ9E/ucd+pH/Kf7+XhFH5mM1mc3hsjHGall917NjR/u/atWurSZMmqly5subOnWu/GNz11FcQtkFO1JXZ/Pmp9l69etn/XatWLTVs2FDly5fXN998o27dumW5XH6tc9iwYfrtt9+0Zs0ap+fcaX9mVae77M9q1appy5YtOnXqlBYuXKj+/ftr1apVWY6voO7LrOqsWbOmW+zLP//8U48++qiWLVsmf3//LOdzl/2J3EEP5awgbAN3/712h/+jr+QJPRT9k3vsR/qni/LT/uQ0vXwoLCxMhQoVckoWjx8/7pRkFhRBQUGqXbu29uzZY78jzNXqi4iI0Pnz55WQkJDlPPlNTtUVERGhY8eOOa3/77//zre1lypVSuXLl9eePXskFaw6H3nkES1evFgrVqxQmTJl7NPdbX9mVWdmCur+9PX1VZUqVdSwYUNNmjRJdevW1SuvvOJ2+zKrOjNTEPflL7/8ouPHj6tBgwby9vaWt7e3Vq1apVdffVXe3t72MbjL/kTOooeihypIv9cF8f/oy3lCD0X/5B77UaJ/yo/9E2FUPuTr66sGDRooNjbWYXpsbKyioqLyaFQ3JiUlRbt27VKpUqVUsWJFRUREONR3/vx5rVq1yl5fgwYN5OPj4zDP0aNHtX379ny7DXKqriZNmigxMVEbNmywz7N+/XolJibm29pPnDihP//8U6VKlZJUMOo0xmjYsGH64osv9OOPP6pixYoOz7vL/rxWnZkpiPszM8YYpaSkuM2+zEpGnZkpiPuyTZs22rZtm7Zs2WL/adiwofr27astW7aoUqVKbr0/cWPooeihCtLvdUH8P1ryjB6K/on+qaDtywLZP7l0uXNYJuO2xLNnzzY7d+40I0aMMEFBQebAgQN5PbRsefzxx83KlSvNvn37TFxcnOnUqZMJDg62j3/y5MmmSJEi5osvvjDbtm0z99xzT6a3lSxTpoxZvny5+fXXX03r1q3z/LbEycnJZvPmzWbz5s1Gkpk+fbrZvHmz/XbROVVXhw4dTJ06dcy6devMunXrTO3atS29LejV6kxOTjaPP/64Wbt2rdm/f79ZsWKFadKkiSldunSBqnPo0KGmSJEiZuXKlQ63cT179qx9HnfYn9eq013259ixY81PP/1k9u/fb3777Tfz1FNPGS8vL7Ns2TJjjHvsy2vV6S77MjOX3w3GGPfZn8gd9FD0UHn1e+0J/ZMxntFD0T/RPxW0fZmZ/N4/EUblY6+//ropX7688fX1Nf/5z38cbiWa3/Xq1cuUKlXK+Pj4mMjISNOtWzezY8cO+/Pp6elm/PjxJiIiwvj5+ZnmzZubbdu2Oazj33//NcOGDTPFihUzAQEBplOnTubQoUNWl+JgxYoVRpLTT//+/Y0xOVfXiRMnTN++fU1wcLAJDg42ffv2NQkJCRZVefU6z549a9q1a2dKlChhfHx8TLly5Uz//v2dasjvdWZWnyTz/vvv2+dxh/15rTrdZX8OHDjQ/v9liRIlTJs2beyNlDHusS+NuXqd7rIvM3NlM+Uu+xO5hx6KHiovfq89oX8yxjN6KPqniwr6fsxA/3RRftufNmOMce1YKgAAAAAAAOD6cM0oAAAAAAAAWIYwCgAAAAAAAJYhjAIAAAAAAIBlCKMAAAAAAABgGcIoAAAAAAAAWIYwCgAAAAAAAJYhjAIAAAAAAIBlCKMAAAAAAABgGcIoAJY4cOCAbDabtmzZkmuvMWDAAHXt2vWG17N7925FREQoOTn5xgdVgK1cuVI2m02nTp2SJC1ZskT169dXenp63g4MAAAPQg9V8NBDAddGGAXgmgYMGCCbzeb006FDh2yvo2zZsjp69Khq1aqViyPNGU8//bT++9//Kjg4OK+Hkq906tRJNptNH3/8cV4PBQCAAoEeChI9FJAZwigA2dKhQwcdPXrU4Wf+/PnZXr5QoUKKiIiQt7d3Lo7yxh0+fFiLFy/W/fffn9dDUWpqal4Pwcn999+v1157La+HAQBAgUEPZT16KCD/I4wCkC1+fn6KiIhw+AkNDbU/b7PZ9MYbb6hjx44KCAhQxYoV9dlnn9mfv/IQ84SEBPXt21clSpRQQECAqlatqvfff98+/7Zt29S6dWsFBASoePHievDBB3X69Gn782lpaRo5cqSKFi2q4sWLa9SoUTLGOIzZGKOpU6eqUqVKCggIUN26dfX5559ftc5PP/1UdevWVZkyZezTTpw4oXvuuUdlypRRYGCgateu7dBEvvXWWypdurTTodd33nmn+vfvb3/89ddfq0GDBvL391elSpU0YcIEXbhwwWEbvvnmm+rSpYuCgoI0ceJEpaWladCgQapYsaICAgJUrVo1vfLKKw6vc+HCBQ0fPty+LUaPHq3+/fs7HG6fnW3x7bff6qabblJAQIBatWqlAwcOOG2fO++8Uxs2bNC+ffuuuh0BAMBF9FD0UBk10UMBlzEAcA39+/c3Xbp0ueo8kkzx4sXNO++8Y3bv3m3GjRtnChUqZHbu3GmMMWb//v1Gktm8ebMxxpj//ve/pl69embjxo1m//79JjY21ixevNgYY8yZM2dMZGSk6datm9m2bZv54YcfTMWKFU3//v3trzdlyhRTpEgR8/nnn5udO3eaQYMGmeDgYIdxPvXUU6Z69epm6dKlZu/eveb99983fn5+ZuXKlVnW0aVLF/PQQw85TDt8+LB58cUXzebNm83evXvNq6++agoVKmTi4uKMMcacOHHC+Pr6muXLl9uXOXnypPH19TXff/+9McaYpUuXmpCQEDNnzhyzd+9es2zZMlOhQgUTExPjsA1LlixpZs+ebfbu3WsOHDhgzp8/b5599lmzYcMGs2/fPvPRRx+ZwMBAs2DBAvtyEydONMWKFTNffPGF2bVrl3nooYdMSEiIS9vi0KFDxs/Pzzz66KPm999/Nx999JEJDw83kkxCQoLD9ihZsqSZM2dOltsQAABcRA9FD3U5eijgEsIoANfUv39/U6hQIRMUFOTw87///c8+jySnBqRRo0Zm6NChxhjnRqpz587m/vvvz/T13n77bRMaGmpOnz5tn/bNN98YLy8vEx8fb4wxplSpUmby5Mn251NTU02ZMmXszcPp06eNv7+/Wbt2rcO6Bw0aZO65554sa61bt65DXVm5/fbbzeOPP25/fOedd5qBAwfaH7/11lsmIiLCXLhwwRhjzG233WZeeOEFh3V8+OGHplSpUvbHksyIESOu+doPP/ywufvuu+2Pw8PDzYsvvmh/fOHCBVOuXDmXtsXYsWNNjRo1THp6uv350aNHZ9pI1a9f36EBBAAAmaOHckYPRQ8FGGNM/j7xGEC+0apVK73xxhsO04oVK+bwuEmTJk6Ps7rzy9ChQ3X33Xfr119/Vbt27dS1a1dFRUVJknbt2qW6desqKCjIPn/Tpk2Vnp6u3bt3y9/fX0ePHnV4PW9vbzVs2NB+mPnOnTt17tw5RUdHO7zu+fPnVb9+/Szr/Pfff+Xv7+8wLS0tTZMnT9aCBQv0119/KSUlRSkpKQ7j69u3rx588EHNmjVLfn5+mjdvnnr37q1ChQpJkn755Rdt3LhRzz//vMN6z507p7NnzyowMFCS1LBhQ6cxvfnmm3r33Xd18OBB/fvvvzp//rzq1asnSUpMTNSxY8d066232ucvVKiQGjRoYD/kPTvbYteuXWrcuLFsNpv9+Sv3Z4aAgACdPXs2y20IAAAuoYeih8pADwVcQhgFIFuCgoJUpUoVl5e7/IP5ch07dtTBgwf1zTffaPny5WrTpo3++9//atq0aTLGZLlcVtOvlNFEfPPNNypdurTDc35+flkuFxYWpoSEBIdpL730kl5++WXNmDFDtWvXVlBQkEaMGKHz58/b5+ncubPS09P1zTff6JZbbtHq1as1ffp0h/FMmDBB3bp1c3rNyxu3y5sz6eL1Fx577DG99NJLatKkiYKDg/Xiiy9q/fr1DvNduV3MZdd+yM62MFdcK+JqTp48qRIlSmR7fgAAPBk9FD1UBnoo4BLCKAA5Ji4uTvfdd5/D46t9g1aiRAkNGDBAAwYM0G233aYnn3xS06ZNU82aNTV37lydOXPG3lj8/PPP8vLy0k033aQiRYqoVKlSiouLU/PmzSVdvADlL7/8ov/85z+SpJo1a8rPz0+HDh1SixYtsl1D/fr1tXPnTodpq1evVpcuXXTvvfdKutiY7NmzRzVq1LDPExAQoG7dumnevHn6448/dNNNN6lBgwb25//zn/9o9+7dLjejq1evVlRUlB5++GH7tL1799r/XaRIEYWHh2vDhg267bbbJF38tnDz5s32b/6ysy1q1qypL7/80mFaXFyc03znzp3T3r17r7pfAQCAa+ih6KEAT0MYBSBbUlJSFB8f7zDN29tbYWFh9sefffaZGjZsqGbNmmnevHnasGGDZs+enen6nn32WTVo0EA333yzUlJStGTJEntj0rdvX40fP179+/dXTEyM/v77bz3yyCPq16+fwsPDJUmPPvqoJk+erKpVq6pGjRqaPn26Tp06ZV9/cHCwnnjiCT322GNKT09Xs2bNlJSUpLVr16pw4cIOd2i5XPv27fXAAw8oLS3Nfnh4lSpVtHDhQq1du1ahoaGaPn264uPjHRqpjHF37txZO3bssDddl9fbqVMnlS1bVj169JCXl5d+++03bdu2TRMnTsxyu1epUkUffPCBvv/+e1WsWFEffvihNm7cqIoVK9rneeSRRzRp0iRVqVJF1atX12uvvaaEhAT7N33Z2RYPPfSQXnrpJY0cOVJDhgzRL7/8ojlz5jiNJy4uTn5+flkefg4AABzRQ9FDSfRQgJO8u1wVgIKif//+RpLTT7Vq1ezzSDKvv/66iY6ONn5+fqZ8+fJm/vz59uevvPjmc889Z2rUqGECAgJMsWLFTJcuXcy+ffvs8//222+mVatWxt/f3xQrVswMHjzYJCcn259PTU01jz76qAkJCTFFixY1I0eONPfdd5/D3U/S09PNK6+8YqpVq2Z8fHxMiRIlTPv27c2qVauyrPXChQumdOnSZunSpfZpJ06cMF26dDGFCxc2JUuWNOPGjXN6rYxlS5UqZSSZvXv3Oq176dKlJioqygQEBJiQkBBz6623mrffftthGy5atMhhmXPnzpkBAwaYIkWKmKJFi5qhQ4eaMWPGmLp16zpsi2HDhpmQkBATGhpqRo8ebXr06GF69+7t0rb4+uuvTZUqVYyfn5+57bbbzHvvved08c0HH3zQDBkyJMvtBwAALqGHoofKQA8FOLIZ48JJrgCQBZvNpkWLFqlr1655PZQbNmvWLH311Vf6/vvv83oo1yU9PV01atRQz5499dxzz+XYev/++29Vr15dmzZtcvhWEQAAXD96qPyDHgqwDqfpAcAVHnzwQSUkJCg5OVnBwcF5PZxrOnjwoJYtW6YWLVooJSVFM2fO1P79+9WnT58cfZ39+/dr1qxZNFEAACBT9FCZo4cCnHFkFIAc4U7f6hU0f/75p3r37q3t27fLGKNatWpp8uTJ9guTAgCA/IseKu/QQwF5hzAKAAAAAAAAlvHK6wEAAAAAAADAcxBGAQAAAAAAwDKEUQAAAAAAALAMYRQAAAAAAAAsQxgFAAAAAAAAyxBGAQAAAAAAwDKEUQAAAAAAALAMYRQAAAAAAAAsQxgFAAAAAAAAy/w/UJ1xBJ5X9e4AAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 1200x600 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    \n",
        "\n",
        "    # --- Select World and Agent ---\n",
        "    \n",
        "    # current_world = w1p\n",
        "    current_world = w1m\n",
        "    # current_world = w1g\n",
        "    # current_world = w2p\n",
        "    # current_world = w2m\n",
        "    # current_world = w2g\n",
        "    # current_world = w3p\n",
        "    # current_world = w3m\n",
        "    # current_world = w3g\n",
        "    # current_world = w4p\n",
        "    # current_world = w4m\n",
        "    # current_world = w4g\n",
        "    # current_world = w5\n",
        "    initial_agent_state = (0, 0) # Common starting point\n",
        "    agent = Agent(current_world, initial_agent_state)\n",
        "    \n",
        "    printMap(current_world)\n",
        "\n",
        "    print(f\"\\nSelected World: Map shown above.\")\n",
        "    print(f\"Agent Initial State: {initial_agent_state}\")\n",
        "    print(\"-\" * 30)\n",
        "    \n",
        "    common_config = {\n",
        "            'learning_rate': 0.15,         # Tasa de aprendizaje (alpha)\n",
        "            'discount_factor': 0.98,      # Factor de descuento (gamma)\n",
        "            'initial_epsilon': 0.3,       # Tasa inicial de exploración\n",
        "            'epsilon_decay': 0.997,       # Factor de decaimiento de epsilon\n",
        "            'min_epsilon': 0.02,          # Valor mínimo de epsilon\n",
        "            'epsilon_decay_interval': 20, # Intervalo (en episodios) para decaer epsilon\n",
        "            'num_episodes': 4000,         # Número total de episodios\n",
        "            'max_steps_per_episode': current_world.size[0] * current_world.size[1] * 3,  # Límite de pasos\n",
        "            'seed': SEED,                 # Semilla aleatoria\n",
        "            'update_rule': 'q_learning',  # 'q_learning' o 'sarsa'\n",
        "            'verbose': False,             # Mostrar progreso y políticas\n",
        "            'eval_interval': 100,         # Intervalo de evaluación en episodios\n",
        "            'initial_state': INITIAL_STATE  # Posición inicial del agente\n",
        "        }\n",
        "\n",
        "    # --- SARSA ---\n",
        "    print(\"\\n\" + \"=\"*40)\n",
        "    print(\"RUNNING NEW SARSA IMPLEMENTATION\")\n",
        "    print(\"=\"*40)\n",
        "    sarsa_policy_new, sarsa_learner = run_sarsa_new(\n",
        "        current_world,\n",
        "        Agent,\n",
        "        ACTIONS,\n",
        "        common_config.copy()\n",
        "    )\n",
        "    print(\"\\nSARSA Final Policy:\")\n",
        "    printPolicy(current_world, sarsa_policy_new)\n",
        "    if sarsa_learner.best_path_length != float('inf'):\n",
        "        print(f\"SARSA Best Path Length Found: {sarsa_learner.best_path_length}\")\n",
        "    else:\n",
        "        print(\"SARSA did not definitively converge to a goal policy.\")\n",
        "\n",
        "\n",
        "    # --- Q-Learning ---\n",
        "    print(\"\\n\" + \"=\"*40)\n",
        "    print(\"RUNNING NEW Q-LEARNING IMPLEMENTATION\")\n",
        "    print(\"=\"*40)\n",
        "    qlearning_policy_new, qlearning_learner = run_q_learning_new(\n",
        "        current_world,\n",
        "        Agent,\n",
        "        ACTIONS,\n",
        "        common_config.copy()\n",
        "    )\n",
        "    print(\"\\nQ-Learning Final Policy:\")\n",
        "    printPolicy(current_world, qlearning_policy_new)\n",
        "    if qlearning_learner.best_path_length != float('inf'):\n",
        "        print(f\"Q-Learning Best Path Length Found: {qlearning_learner.best_path_length}\")\n",
        "    else:\n",
        "        print(\"Q-Learning did not definitively converge to a goal policy.\")\n",
        "\n",
        "\n",
        "    # --- Mostrar Mapas ---\n",
        "    try:\n",
        "        import matplotlib.pyplot as plt\n",
        "        plt.figure(figsize=(12, 6))\n",
        "\n",
        "        def moving_average(data, window_size=50):\n",
        "            if len(data) < window_size: return data\n",
        "            return np.convolve(data, np.ones(window_size)/window_size, mode='valid')\n",
        "\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.plot(moving_average(sarsa_learner.episode_rewards))\n",
        "        plt.title(f\"SARSA New - Episode Rewards (MA)\")\n",
        "        plt.xlabel(\"Episode (averaged)\")\n",
        "        plt.ylabel(\"Average Reward\")\n",
        "        plt.grid(True)\n",
        "\n",
        "        plt.subplot(1, 2, 2)\n",
        "        plt.plot(moving_average(qlearning_learner.episode_rewards))\n",
        "        plt.title(f\"Q-Learning New - Episode Rewards (MA)\")\n",
        "        plt.xlabel(\"Episode (averaged)\")\n",
        "        plt.ylabel(\"Average Reward\")\n",
        "        plt.grid(True)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    except ImportError:\n",
        "        print(\"\\nMatplotlib not found. Skipping reward plot.\")\n",
        "    except Exception as e:\n",
        "        print(f\"\\nError plotting rewards: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sz-SqcMCynS5"
      },
      "source": [
        "## Análisis:\n",
        "\n",
        "*SARSA* y *Q-Learning* son dos algoritmos muy parecidos, que se pueden aplicar en los mismos problemas y suelen encontrar soluciones similares. No obstante, los resultados de ambos algoritmos pueden diferir en ciertos problemas: por ejemplo, hay un problema llamado Cliffworld en el que SARSA encuentra soluciones más seguras y con menos valor, mientras que Q-Learning asume más riesgos y consigue más valor ([artículo interesante](https://medium.com/gradientcrescent/fundamentals-of-reinforcement-learning-navigating-cliffworld-with-sarsa-and-q-learning-cc3c36eb5830))."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zD_2_U4PDvPG"
      },
      "source": [
        "## Ejercicio 2:\n",
        "\n",
        "Analizad los resultados obtenidos por ambos algoritmos en los escenarios de prueba. Algunos posibles análisis se muestran a continuación, no es necesario que hagáis todos.\n",
        "\n",
        "1.   Comentad el rendimiento que observáis en ambos algoritmos. ¿Qué problemas son capaces de resolver? ¿En cuáles no encuentran la solución óptima? ¿A qué se puede deber este comportamiento?\n",
        "\n",
        "2.   Comentad las diferencias entre los algoritmos en los diferentes escenarios: ¿Cuál resuelve más escenarios? ¿Cuál converge más rápido? ¿Cuál genera más valor? ¿Hay diferencias en la gestión de riesgos en los agujeros de gusano y las catapultas?\n",
        "\n",
        "3.   Comentad las diferencias cuando se aplica una mayor exploración ($\\epsilon$ más alto) y una mayor explotación ($\\epsilon$ más bajo). ¿Cuál converge más rápido? ¿Cuál obtiene más valor? ¿Qué estrategia piensas que podría usarse para explorar y explotar de forma más inteligente?\n",
        "\n",
        "Nota: Las siguientes variables pueden ser interesantes para valorar los resultados: Diferencia entre la política resultante y la política óptima, número de iteraciones necesarias para converger, retorno total del problema y retorno obtenido en cada episodio."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CsgY-j6xDusN"
      },
      "outputs": [],
      "source": [
        "# Resolución: Código necesario para generar y comparar los resultados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "033NFu_EFd3z"
      },
      "source": [
        "Resolución: Comentarios sobre los resultados\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YGmGEpZxzbT0"
      },
      "source": [
        "## Ejercicio 3:\n",
        "\n",
        "Imaginad que queremos desarrollar un agente \"estúpido\" que caiga en los obstáculos más cercanos en lugar de evitarlos para alcanzar el objetivo. Para ello sólo tenemos que cambiar el sistema de refuerzos que recibe el agente al realizar acciones en los estados. Nuestros algoritmos de SARSA y Q-Learning deberían hacer el resto sin necesidad de modificaciones.\n",
        "\n",
        "1. Programad una función de refuerzo para la clase agente modificada que se muestra en el siguiente bloque de código que permita entrenar al agente \"estúpido\".\n",
        "\n",
        "2. Aplicad SARSA y QLearning al nuevo agente \"estúpido\" en algunos de los laberintos generados previamente. Sugerencia: para una mejor exploración, en lugar de iniciar los episodios en el origen, iniciarlos en estados aleatorios. ¿Cuál es su comportamiento? ¿Alcanza el objetivo? ¿Consigue caer en todos los obstáculos?\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZzTXT2_B0zTP"
      },
      "outputs": [],
      "source": [
        "class StupidAgent:\n",
        "\n",
        "  def __init__(self, world, initialState):\n",
        "    # Crea un agente\n",
        "    self.world = world\n",
        "    self.state = np.array(initialState)\n",
        "\n",
        "  def move(self, state, action):\n",
        "    # Gestiona las transiciones de estados\n",
        "    nextState = state + np.array(action)\n",
        "    if nextState[0] < 0:\n",
        "      nextState[0] = 0\n",
        "    elif nextState[0] >= self.world.size[0]:\n",
        "      nextState[0] = self.world.size[0] - 1\n",
        "    if nextState[1] < 0:\n",
        "      nextState[1] = 0\n",
        "    elif nextState[1] >= self.world.size[1]:\n",
        "      nextState[1] = self.world.size[1] - 1\n",
        "    if self.world.map[(nextState[0], nextState[1])] == 2:\n",
        "      aux = nextState\n",
        "      for i in range(self.world.size[0]):\n",
        "        for j in range(self.world.size[1]):\n",
        "          if self.world.map[(i, j)] == 2 and (nextState[0] != i and nextState[1] != j):\n",
        "            aux = np.array([i, j])\n",
        "            nextState = aux\n",
        "    if self.world.map[(nextState[0], nextState[1])] == 3:\n",
        "      if action == (1, 0):\n",
        "        nextState = np.array([np.random.randint(nextState[0], self.world.size[0]-1), nextState[1]])\n",
        "      elif action == (-1, 0):\n",
        "        nextState = np.array([np.random.randint(0, nextState[0]), nextState[1]])\n",
        "      elif action == (0, 1):\n",
        "        nextState = np.array([nextState[0], np.random.randint(nextState[1], self.world.size[1]-1)])\n",
        "      elif action == (0, -1):\n",
        "        nextState = np.array([nextState[0], np.random.randint(0, nextState[1])])\n",
        "    return nextState\n",
        "\n",
        "  def reward(self, nextState):\n",
        "    # Gestiona los refuerzos\n",
        "    reward = 0\n",
        "    # EDITAR LA FUNCION\n",
        "    return reward\n",
        "\n",
        "  def checkAction(self, state, action):\n",
        "    # Planifica una acción\n",
        "    nextState = self.move(state, action)\n",
        "    if self.world.map[(state[0], state[1])] == -1:\n",
        "      nextState = state\n",
        "    reward = self.reward(nextState)\n",
        "    return nextState, reward\n",
        "\n",
        "  def executeAction(self, action):\n",
        "    # Planifica y ejecuta una acción\n",
        "    nextState = self.move(self.state, action)\n",
        "    if self.world.map[(self.state[0], self.state[1])] == -1:\n",
        "      nextState = self.state\n",
        "    else:\n",
        "      self.state = nextState\n",
        "    reward = self.reward(nextState)\n",
        "    return self.state, reward"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lI3eGmd61ldg"
      },
      "outputs": [],
      "source": [
        "# Resolución: Código necesario para generar y comparar los resultados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VcDd6yb81tHu"
      },
      "source": [
        "Resolución: Comentarios sobre los resultados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EFAm3ACTJW9k"
      },
      "source": [
        "Nota: Sentíos libres de añadir los bloques de código y texto necesarios para responder las preguntas."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
